"""
AIæ™ºèƒ½å·¥ä½œæµFastAPIè·¯ç”±
ä¸ºå‰ç«¯æä¾›æ™ºèƒ½åŒ–å·¥ä½œæµç”Ÿæˆå’ŒèŠ‚ç‚¹é…ç½®çš„FastAPIæŽ¥å£
"""
import json
import logging
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from ai.intelligent_node_configurator import IntelligentNodeConfigurator, NodeType, NodeConfigRequest
from ai.intelligent_workflow_orchestrator import IntelligentWorkflowOrchestrator


# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/api/intelligent-workflow", tags=["intelligent-workflow"])

# å…¨å±€å®žä¾‹
node_configurator = None
workflow_orchestrator = None
logger = logging.getLogger(__name__)


# è¯·æ±‚æ¨¡åž‹
class WorkflowGenerationRequest(BaseModel):
    description: str
    context: Dict[str, Any] = {}


class NodeConfigurationRequest(BaseModel):
    nodeType: str
    description: str = ""
    context: Dict[str, Any] = {}
    workflowContext: Dict[str, Any] = {}
    existingConfig: Dict[str, Any] = {}


class RequirementsAnalysisRequest(BaseModel):
    input: str
    context: Dict[str, Any] = {}


class WorkflowOptimizationRequest(BaseModel):
    workflow: Dict[str, Any]
    optimizationGoals: List[str] = ["performance"]


class ConnectionSuggestionRequest(BaseModel):
    nodes: List[Dict[str, Any]]
    context: Dict[str, Any] = {}


class WorkflowValidationRequest(BaseModel):
    workflow: Dict[str, Any]


async def initialize_services():
    """åˆå§‹åŒ–æœåŠ¡"""
    global node_configurator, workflow_orchestrator
    
    if node_configurator is None:
        node_configurator = IntelligentNodeConfigurator()
        await node_configurator.initialize()
    
    if workflow_orchestrator is None:
        workflow_orchestrator = IntelligentWorkflowOrchestrator()
        await workflow_orchestrator.initialize()


@router.post("/generate")
async def generate_intelligent_workflow(request: WorkflowGenerationRequest):
    """ç”Ÿæˆæ™ºèƒ½å·¥ä½œæµ"""
    try:
        await initialize_services()
        
        if not request.description:
            raise HTTPException(status_code=400, detail="è¯·æä¾›å·¥ä½œæµæè¿°")
        
        logger.info(f"ðŸŽ¯ ç”Ÿæˆæ™ºèƒ½å·¥ä½œæµè¯·æ±‚: {request.description[:50]}...")
        
        # ç”Ÿæˆæ™ºèƒ½å·¥ä½œæµ
        workflow = await workflow_orchestrator.generate_intelligent_workflow(
            request.description, request.context
        )
        
        # è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼
        frontend_workflow = _convert_to_frontend_format(workflow)
        
        return {
            "success": True,
            "workflow": frontend_workflow,
            "metadata": {
                "workflow_id": workflow.id,
                "workflow_name": workflow.name,
                "created_at": workflow.metadata.get("created_at"),
                "optimization_info": workflow.optimization_info
            }
        }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ™ºèƒ½å·¥ä½œæµå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/configure-node")
async def configure_intelligent_node(request: NodeConfigurationRequest):
    """æ™ºèƒ½é…ç½®èŠ‚ç‚¹"""
    try:
        await initialize_services()
        
        if not request.nodeType:
            raise HTTPException(status_code=400, detail="è¯·æŒ‡å®šèŠ‚ç‚¹ç±»åž‹")
        
        try:
            node_type = NodeType(request.nodeType)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„èŠ‚ç‚¹ç±»åž‹: {request.nodeType}")
        
        logger.info(f"ðŸ”§ æ™ºèƒ½é…ç½®èŠ‚ç‚¹è¯·æ±‚: {request.nodeType}")
        
        # åˆ›å»ºé…ç½®è¯·æ±‚
        config_request = NodeConfigRequest(
            node_type=node_type,
            user_description=request.description,
            context=request.context,
            workflow_context=request.workflowContext,
            existing_config=request.existingConfig
        )
        
        # ç”Ÿæˆæ™ºèƒ½é…ç½®
        config_response = await node_configurator.configure_node(config_request)
        
        return {
            "success": config_response.success,
            "config": config_response.config,
            "reasoning": config_response.reasoning,
            "confidence": config_response.confidence,
            "suggestions": config_response.suggestions,
            "optimizations": config_response.optimizations
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ™ºèƒ½é…ç½®èŠ‚ç‚¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/analyze-requirements")
async def analyze_workflow_requirements(request: RequirementsAnalysisRequest):
    """åˆ†æžå·¥ä½œæµéœ€æ±‚"""
    try:
        await initialize_services()
        
        if not request.input:
            raise HTTPException(status_code=400, detail="è¯·æä¾›éœ€æ±‚æè¿°")
        
        logger.info(f"ðŸ” åˆ†æžå·¥ä½œæµéœ€æ±‚: {request.input[:50]}...")
        
        # ä½¿ç”¨å·¥ä½œæµç¼–æŽ’å™¨çš„åˆ†æžåŠŸèƒ½
        analysis = await workflow_orchestrator._analyze_workflow_requirements(request.input, request.context)
        
        return {
            "success": True,
            "analysis": analysis,
            "recommendations": {
                "suggested_nodes": analysis.get("required_nodes", []),
                "connection_style": analysis.get("connection_style", "linear"),
                "complexity": analysis.get("complexity", "moderate"),
                "optimization_goals": analysis.get("optimization_goals", [])
            }
        }
        
    except Exception as e:
        logger.error(f"åˆ†æžå·¥ä½œæµéœ€æ±‚å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/optimize-workflow")
async def optimize_existing_workflow(request: WorkflowOptimizationRequest):
    """ä¼˜åŒ–çŽ°æœ‰å·¥ä½œæµ"""
    try:
        await initialize_services()
        
        if not request.workflow:
            raise HTTPException(status_code=400, detail="è¯·æä¾›å·¥ä½œæµæ•°æ®")
        
        logger.info("ðŸš€ ä¼˜åŒ–çŽ°æœ‰å·¥ä½œæµ")
        
        # è½¬æ¢å‰ç«¯æ ¼å¼åˆ°å†…éƒ¨æ ¼å¼
        nodes, connections = _convert_from_frontend_format(request.workflow)
        
        # æ‰§è¡Œä¼˜åŒ–
        optimization_result = await workflow_orchestrator._optimize_workflow(
            nodes, connections, {"optimization_goals": request.optimizationGoals}
        )
        
        # è½¬æ¢å›žå‰ç«¯æ ¼å¼
        optimized_workflow = _convert_optimization_to_frontend(optimization_result)
        
        return {
            "success": True,
            "optimizedWorkflow": optimized_workflow,
            "optimizationInfo": optimization_result.get("optimization_info", {}),
            "improvements": _calculate_improvements(request.workflow, optimized_workflow)
        }
        
    except Exception as e:
        logger.error(f"ä¼˜åŒ–å·¥ä½œæµå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/suggest-connections")
async def suggest_intelligent_connections(request: ConnectionSuggestionRequest):
    """å»ºè®®æ™ºèƒ½è¿žæŽ¥"""
    try:
        await initialize_services()
        
        if not request.nodes:
            raise HTTPException(status_code=400, detail="è¯·æä¾›èŠ‚ç‚¹æ•°æ®")
        
        logger.info("ðŸ”— ç”Ÿæˆæ™ºèƒ½è¿žæŽ¥å»ºè®®")
        
        # åˆ†æžèŠ‚ç‚¹å¹¶ç”Ÿæˆè¿žæŽ¥å»ºè®®
        connection_suggestions = await _generate_connection_suggestions(request.nodes, request.context)
        
        return {
            "success": True,
            "suggestions": connection_suggestions,
            "reasoning": "åŸºäºŽèŠ‚ç‚¹ç±»åž‹å’ŒåŠŸèƒ½åˆ†æžç”Ÿæˆçš„æ™ºèƒ½è¿žæŽ¥å»ºè®®"
        }
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆè¿žæŽ¥å»ºè®®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/validate-workflow")
async def validate_workflow(request: WorkflowValidationRequest):
    """éªŒè¯å·¥ä½œæµ"""
    try:
        await initialize_services()
        
        if not request.workflow:
            raise HTTPException(status_code=400, detail="è¯·æä¾›å·¥ä½œæµæ•°æ®")
        
        logger.info("âœ… éªŒè¯å·¥ä½œæµ")
        
        # è½¬æ¢æ ¼å¼å¹¶éªŒè¯
        nodes, connections = _convert_from_frontend_format(request.workflow)
        validation_result = await workflow_orchestrator._validate_workflow({
            "nodes": nodes,
            "connections": connections
        })
        
        return {
            "success": True,
            "validation": validation_result,
            "isValid": validation_result.get("valid", False),
            "issues": validation_result.get("issues", []),
            "warnings": validation_result.get("warnings", []),
            "suggestions": validation_result.get("suggestions", [])
        }
        
    except Exception as e:
        logger.error(f"éªŒè¯å·¥ä½œæµå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _convert_to_frontend_format(workflow):
    """å°†å†…éƒ¨å·¥ä½œæµæ ¼å¼è½¬æ¢ä¸ºå‰ç«¯æ ¼å¼"""
    frontend_nodes = []
    frontend_edges = []

    # èŠ‚ç‚¹ç±»åž‹æ˜ å°„ï¼šå†…éƒ¨ç±»åž‹ -> å‰ç«¯èŠ‚ç‚¹ç±»åž‹
    node_type_mapping = {
        "material-node": "customNode",  # ææ–™èŠ‚ç‚¹ä½¿ç”¨customNodeæ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        "execution-node": "execution-node",
        "condition-node": "condition-node",
        "result-node": "result-node"
    }

    # è½¬æ¢èŠ‚ç‚¹
    for node in workflow.nodes:
        # æ˜ å°„åˆ°å‰ç«¯çš„å¢žå¼ºåž‹èŠ‚ç‚¹ç±»åž‹
        frontend_type = node_type_mapping.get(node.type.value, node.type.value)

        frontend_node = {
            "id": node.id,
            "type": frontend_type,
            "position": node.position,
            "data": {
                "label": _generate_node_label(node),
                "nodeType": node.type.value,  # ä½¿ç”¨åŽŸå§‹èŠ‚ç‚¹ç±»åž‹ï¼Œè®©å‰ç«¯æ­£ç¡®è¯†åˆ«
                "status": "default",  # æ™®é€šèŠ‚ç‚¹çš„é»˜è®¤çŠ¶æ€
                # ç§»é™¤å¢žå¼ºåž‹èŠ‚ç‚¹ç‰¹æœ‰çš„å±žæ€§ï¼Œä½¿ç”¨æ™®é€šèŠ‚ç‚¹æ ¼å¼
                # "config": node.config,  # æ™®é€šèŠ‚ç‚¹ä¸éœ€è¦å¤æ‚é…ç½®
                # "intelligentConfig": True,
                # "aiEnhanced": True,
                # "typeIcon": _get_node_icon(node.type),
                # "progress": 0
            }
        }
        frontend_nodes.append(frontend_node)
    
    # è½¬æ¢è¿žæŽ¥
    for connection in workflow.connections:
        # æ ¹æ®è¿žæŽ¥ç±»åž‹ç¡®å®šsourceHandleå’ŒtargetHandle
        # æ–°ç‰ˆèŠ‚ç‚¹ä½¿ç”¨å¤åˆIDæ ¼å¼ï¼šdirection-type
        source_handle = "right-source"  # é»˜è®¤ä»Žå³ä¾§è¾“å‡º
        target_handle = "left-target"   # é»˜è®¤ä»Žå·¦ä¾§è¾“å…¥

        # å¦‚æžœæ˜¯æ¡ä»¶èŠ‚ç‚¹ï¼Œä½¿ç”¨ç‰¹å®šçš„handle
        if connection.type.value == "conditional":
            source_handle = "right-true"  # æ¡ä»¶ä¸ºçœŸçš„è¾“å‡º

        frontend_edge = {
            "id": connection.id,
            "source": connection.source,
            "target": connection.target,
            "sourceHandle": source_handle,
            "targetHandle": target_handle,
            "type": "enhanced",  # ä½¿ç”¨ä¸Žå‰ç«¯ä¸€è‡´çš„è¿žæŽ¥çº¿ç±»åž‹
            "animated": False,
            "className": "silky-smooth enhanced-edge",
            "style": {"strokeWidth": 2, "stroke": "#7c3aed"},
            "markerEnd": "url(#smooth-arrow)",
            "data": {
                "connectionType": connection.type.value,
                "conditions": connection.conditions,
                "metadata": connection.metadata,
                "status": "connected",
                "color": "#7c3aed",
                "aiGenerated": True
            }
        }
        frontend_edges.append(frontend_edge)
    
    return {
        "nodes": frontend_nodes,
        "edges": frontend_edges,
        "metadata": workflow.metadata
    }


def _generate_node_label(node):
    """ç”ŸæˆèŠ‚ç‚¹æ ‡ç­¾"""
    type_labels = {
        NodeType.MATERIAL: "ææ–™",
        NodeType.EXECUTION: "æ‰§è¡Œ",
        NodeType.CONDITION: "æ¡ä»¶",
        NodeType.RESULT: "ç»“æžœ"
    }
    return type_labels.get(node.type, node.type.value)


def _get_node_icon(node_type):
    """èŽ·å–èŠ‚ç‚¹å›¾æ ‡"""
    type_icons = {
        NodeType.MATERIAL: "ðŸ“",
        NodeType.EXECUTION: "âš¡",
        NodeType.CONDITION: "ðŸ”€",
        NodeType.RESULT: "ðŸ“„"
    }
    return type_icons.get(node_type, "ðŸ”§")


def _convert_from_frontend_format(workflow_data):
    """å°†å‰ç«¯æ ¼å¼è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼"""
    # è¿™é‡Œéœ€è¦å®žçŽ°è½¬æ¢é€»è¾‘
    # æš‚æ—¶è¿”å›žç©ºåˆ—è¡¨ï¼Œå®žé™…å®žçŽ°æ—¶éœ€è¦å®Œå–„
    return [], []


def _convert_optimization_to_frontend(optimization_result):
    """å°†ä¼˜åŒ–ç»“æžœè½¬æ¢ä¸ºå‰ç«¯æ ¼å¼"""
    # è¿™é‡Œéœ€è¦å®žçŽ°è½¬æ¢é€»è¾‘
    return optimization_result


def _calculate_improvements(original, optimized):
    """è®¡ç®—æ”¹è¿›æŒ‡æ ‡"""
    return {
        "performance_improvement": "é¢„è®¡æå‡30%",
        "resource_savings": "é¢„è®¡èŠ‚çœ20%å†…å­˜",
        "accuracy_improvement": "é¢„è®¡æå‡15%å‡†ç¡®çŽ‡"
    }


async def _generate_connection_suggestions(nodes, context):
    """ç”Ÿæˆè¿žæŽ¥å»ºè®®"""
    suggestions = []
    
    # åŸºç¡€è¿žæŽ¥é€»è¾‘
    for i in range(len(nodes) - 1):
        current_node = nodes[i]
        next_node = nodes[i + 1]
        
        suggestion = {
            "source": current_node.get("id"),
            "target": next_node.get("id"),
            "type": "sequential",
            "confidence": 0.8,
            "reasoning": f"åŸºäºŽèŠ‚ç‚¹ç±»åž‹ {current_node.get('type')} -> {next_node.get('type')} çš„æ ‡å‡†è¿žæŽ¥"
        }
        suggestions.append(suggestion)
    
    return suggestions
