"""
æ™ºèƒ½è§„åˆ’å™¨ - ç²¾å‡†ç†è§£ç”¨æˆ·æ„å›¾å¹¶ç”Ÿæˆæ¸…æ™°çš„æ‰§è¡Œæ­¥éª¤
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai.brain_system.semantic_understanding import SemanticUnderstandingModule
from ai.brain_system.brain_core import IntelligentBrain
from agent_system.agent_factory import AgentFactory
from ai.role_template_manager import role_template_manager


class IntelligentPlanner:
    """æ™ºèƒ½è§„åˆ’å™¨ - ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.semantic_module = SemanticUnderstandingModule()
        self.brain = IntelligentBrain()
        self.conversation_history = []

        # å¢å¼ºè®°å¿†ç³»ç»Ÿ
        self.user_preferences = {}  # ç”¨æˆ·åå¥½è®°å¿†
        self.task_patterns = {}     # ä»»åŠ¡æ¨¡å¼è®°å¿†
        self.context_keywords = []  # ä¸Šä¸‹æ–‡å…³é”®è¯
        self.session_summary = ""   # ä¼šè¯æ‘˜è¦

    async def quick_response(self, user_input: str, intent: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        å¿«é€Ÿå“åº”æ¨¡å¼ - ç”¨äºèŠå¤©å’Œç®€å•é—®ç­”

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            intent: å·²è¯†åˆ«çš„æ„å›¾
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            å¿«é€Ÿå“åº”ç»“æœ
        """
        self.logger.info(f"âš¡ [IntelligentPlanner] å¿«é€Ÿå“åº”æ¨¡å¼: {intent}")

        try:
            # æ ¹æ®æ„å›¾é€‰æ‹©è§’è‰²
            role_name = role_template_manager.get_role_by_intent(intent)
            self.logger.info(f"ğŸ­ [IntelligentPlanner] é€‰æ‹©è§’è‰²: {role_name}")

            # å‡†å¤‡æ¨¡æ¿å˜é‡
            template_vars = {
                'user_input': user_input,
                'domain': context.get('domain', 'é€šç”¨') if context else 'é€šç”¨',
                'context': context.get('background', 'æ— ç‰¹æ®ŠèƒŒæ™¯') if context else 'æ— ç‰¹æ®ŠèƒŒæ™¯'
            }

            # æ¸²æŸ“è§’è‰²æ¨¡æ¿
            role_prompt = role_template_manager.render_template(role_name, **template_vars)

            # è°ƒç”¨AIç”Ÿæˆå“åº”
            ai_response = await AgentFactory.ask_llm(role_prompt)

            # è®°å½•å¯¹è¯å†å²
            self._add_to_history("user", user_input)
            self._add_to_history("assistant", ai_response)

            return {
                'status': 'success',
                'response_type': 'quick_chat' if intent == 'casual_chat' else 'quick_answer',
                'message': ai_response.strip(),
                'role': role_name,
                'intent': intent,
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            self.logger.error(f"âŒ [IntelligentPlanner] å¿«é€Ÿå“åº”å¤±è´¥: {e}")
            return {
                'status': 'error',
                'message': f"å¿«é€Ÿå“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                'timestamp': datetime.now().isoformat()
            }

    async def role_based_response(self, user_input: str, intent: str, context: Optional[Dict] = None, response_mode: str = "quick") -> Dict[str, Any]:
        """
        åŸºäºè§’è‰²æ¨¡æ¿çš„ç»Ÿä¸€å“åº”æ–¹æ³•

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            intent: å·²è¯†åˆ«çš„æ„å›¾
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            response_mode: å“åº”æ¨¡å¼ ("quick" æˆ– "deep")

        Returns:
            è§’è‰²å“åº”ç»“æœ
        """
        self.logger.info(f"ğŸ­ [IntelligentPlanner] è§’è‰²å“åº”æ¨¡å¼: {intent} ({response_mode})")

        try:
            # æ ¹æ®æ„å›¾é€‰æ‹©è§’è‰²
            role_name = role_template_manager.get_role_by_intent(intent)
            self.logger.info(f"ğŸ­ [IntelligentPlanner] é€‰æ‹©è§’è‰²: {role_name}")

            # å‡†å¤‡æ¨¡æ¿å˜é‡
            template_vars = {
                'user_input': user_input,
                'domain': context.get('domain', 'é€šç”¨') if context else 'é€šç”¨',
                'context': context.get('background', 'æ— ç‰¹æ®ŠèƒŒæ™¯') if context else 'æ— ç‰¹æ®ŠèƒŒæ™¯'
            }

            # æ ¹æ®å“åº”æ¨¡å¼è°ƒæ•´æ¨¡æ¿å˜é‡
            if response_mode == "deep":
                # æ·±åº¦æ¨¡å¼éœ€è¦æ›´å¤šå˜é‡
                template_vars.update({
                    'analysis_depth': 'è¯¦ç»†åˆ†æ',
                    'output_format': 'ç»“æ„åŒ–æ­¥éª¤',
                    'complexity_level': 'é«˜'
                })

            # æ¸²æŸ“è§’è‰²æ¨¡æ¿
            role_prompt = role_template_manager.render_template(role_name, **template_vars)

            # è°ƒç”¨AIç”Ÿæˆå“åº”
            ai_response = await AgentFactory.ask_llm(role_prompt)

            # è®°å½•å¯¹è¯å†å²
            self._add_to_history("user", user_input)
            self._add_to_history("assistant", ai_response)

            # æ ¹æ®å“åº”æ¨¡å¼ç¡®å®šå“åº”ç±»å‹
            if response_mode == "quick":
                response_type = 'quick_chat' if intent == 'casual_chat' else 'quick_answer'
            else:
                response_type = 'execution_plan' if intent == 'task_planning' else 'detailed_analysis'

            return {
                'status': 'success',
                'response_type': response_type,
                'message': ai_response.strip(),
                'role': role_name,
                'intent': intent,
                'response_mode': response_mode,
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            self.logger.error(f"âŒ [IntelligentPlanner] è§’è‰²å“åº”å¤±è´¥: {e}")
            return {
                'status': 'error',
                'message': f"è§’è‰²å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                'timestamp': datetime.now().isoformat()
            }

    async def process_user_request(self, user_input: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¯·æ±‚çš„ä¸»å…¥å£
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„éœ€æ±‚æè¿°
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            åŒ…å«ç†è§£ç»“æœå’Œæ‰§è¡Œè®¡åˆ’çš„å­—å…¸
        """
        self.logger.info(f"ğŸš€ [IntelligentPlanner] å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚: {user_input[:50]}...")
        
        try:
            # è®°å½•å¯¹è¯å†å²
            self._add_to_history("user", user_input)
            
            # ç¬¬ä¸€æ­¥ï¼šæ·±åº¦è¯­ä¹‰ç†è§£
            understanding_result = await self._deep_understand_request(user_input, context)
            
            # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            planning_result = await self._generate_execution_plan(user_input, understanding_result)
            
            # ç¬¬ä¸‰æ­¥ï¼šæ•´åˆç»“æœ
            final_result = await self._integrate_results(user_input, understanding_result, planning_result)
            
            # è®°å½•AIå“åº”
            self._add_to_history("assistant", final_result)
            
            self.logger.info("âœ… [IntelligentPlanner] ç”¨æˆ·è¯·æ±‚å¤„ç†å®Œæˆ")
            return final_result
            
        except Exception as e:
            self.logger.error(f"âŒ [IntelligentPlanner] å¤„ç†å¤±è´¥: {e}")
            return {
                'status': 'error',
                'message': f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                'timestamp': datetime.now().isoformat()
            }
    
    async def _deep_understand_request(self, user_input: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """æ·±åº¦ç†è§£ç”¨æˆ·è¯·æ±‚"""
        self.logger.debug("ğŸ§  [IntelligentPlanner] æ‰§è¡Œæ·±åº¦è¯­ä¹‰ç†è§£...")
        
        # ä½¿ç”¨å¢å¼ºçš„è¯­ä¹‰ç†è§£æ¨¡å—
        understanding_result = await self.semantic_module.analyze_input(
            user_input, 
            context or {}
        )
        
        # æ·»åŠ å¯¹è¯å†å²ä¸Šä¸‹æ–‡
        if self.conversation_history:
            understanding_result['conversation_context'] = self._get_conversation_context()

        # æ·»åŠ å¢å¼ºè®°å¿†ä¿¡æ¯
        understanding_result['memory_context'] = await self._get_memory_context(user_input)

        # æ›´æ–°è®°å¿†ç³»ç»Ÿ
        await self._update_memory_system(user_input, understanding_result)

        return understanding_result
    
    async def _generate_execution_plan(self, user_input: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        self.logger.debug("ğŸ“‹ [IntelligentPlanner] ç”Ÿæˆæ‰§è¡Œè®¡åˆ’...")
        
        # è·å–æ„å›¾åˆ†æç»“æœ
        intent_analysis = understanding_result.get('intent_analysis', {})
        
        # ä½¿ç”¨è¯­ä¹‰ç†è§£æ¨¡å—çš„ä»»åŠ¡åˆ†è§£åŠŸèƒ½
        planning_result = await self.semantic_module.decompose_to_steps(user_input, intent_analysis)
        
        return planning_result
    
    async def _integrate_results(self, user_input: str, understanding_result: Dict[str, Any], planning_result: Dict[str, Any]) -> Dict[str, Any]:
        """æ•´åˆç†è§£ç»“æœå’Œè§„åˆ’ç»“æœ"""
        self.logger.debug("ğŸ”— [IntelligentPlanner] æ•´åˆç»“æœ...")
        
        # åŸºç¡€ç»“æœç»“æ„
        integrated_result = {
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'user_input': user_input,
            'understanding': understanding_result,
            'planning': planning_result
        }
        
        # æ ¹æ®æ„å›¾ç±»å‹å’Œè§„åˆ’ç±»å‹æ·»åŠ ä¸åŒçš„å“åº”
        primary_intent = understanding_result.get('intent_analysis', {}).get('primary_intent', 'unknown')

        if planning_result.get('type') == 'clarification':
            questions = planning_result.get('questions', [])
            self.logger.info(f"ğŸ”§ [IntelligentPlanner] æ¾„æ¸…é—®é¢˜æ•°é‡: {len(questions)}")
            self.logger.info(f"ğŸ”§ [IntelligentPlanner] æ¾„æ¸…é—®é¢˜å†…å®¹: {questions}")
            integrated_result.update({
                'response_type': 'clarification_needed',
                'message': 'æˆ‘éœ€è¦äº†è§£æ›´å¤šä¿¡æ¯æ¥ä¸ºæ‚¨åˆ¶å®šè¯¦ç»†è®¡åˆ’ï¼š',
                'questions': questions,
                'completeness_score': planning_result.get('completeness_score', 0.5)
            })
        elif primary_intent in ['casual_chat', 'question_answer', 'consultation', 'information_query']:
            # å¤„ç†éä»»åŠ¡è§„åˆ’ç±»å‹çš„äº¤äº’
            integrated_result.update(await self._handle_conversational_intent(
                user_input, primary_intent, understanding_result
            ))
        
        elif planning_result.get('type') == 'steps':
            integrated_result.update({
                'response_type': 'execution_plan',
                'message': 'æˆ‘å·²ç»ä¸ºæ‚¨åˆ¶å®šäº†è¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼š',
                'steps': planning_result.get('steps', []),
                'summary': self._generate_plan_summary(planning_result)
            })
        
        elif planning_result.get('type') == 'error':
            integrated_result.update({
                'status': 'error',
                'response_type': 'error',
                'message': planning_result.get('message', 'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯')
            })
        
        return integrated_result
    
    def _generate_plan_summary(self, planning_result: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè®¡åˆ’æ‘˜è¦"""
        steps = planning_result.get('steps', [])
        
        return {
            'total_steps': planning_result.get('total_steps', len(steps)),
            'estimated_time': planning_result.get('estimated_time', 'æœªçŸ¥'),
            'complexity': planning_result.get('complexity', 'ä¸­ç­‰'),
            'step_names': [step.get('name', f"æ­¥éª¤{step.get('step_id', i+1)}") for i, step in enumerate(steps)]
        }
    
    def _add_to_history(self, role: str, content: Any):
        """æ·»åŠ åˆ°å¯¹è¯å†å²"""
        self.conversation_history.append({
            'role': role,
            'content': content,
            'timestamp': datetime.now().isoformat()
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
    
    def _get_conversation_context(self) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        return self.conversation_history[-6:]  # è¿”å›æœ€è¿‘6è½®å¯¹è¯
    
    async def handle_clarification_response(self, user_response: str, previous_context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·çš„æ¾„æ¸…å›å¤"""
        self.logger.info("ğŸ”„ [IntelligentPlanner] å¤„ç†æ¾„æ¸…å›å¤...")
        
        # å°†æ¾„æ¸…ä¿¡æ¯ä¸åŸå§‹è¯·æ±‚åˆå¹¶
        original_request = previous_context.get('user_input', '')
        enhanced_request = f"{original_request}\n\nè¡¥å……ä¿¡æ¯ï¼š{user_response}"
        
        # é‡æ–°å¤„ç†å¢å¼ºåçš„è¯·æ±‚
        return await self.process_user_request(enhanced_request, previous_context)

    async def _handle_conversational_intent(self, user_input: str, intent_type: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å¯¹è¯ç±»æ„å›¾"""
        self.logger.info(f"ğŸ—£ï¸ [IntelligentPlanner] å¤„ç†å¯¹è¯ç±»æ„å›¾: {intent_type}")

        try:
            if intent_type == 'casual_chat':
                return await self._handle_casual_chat(user_input, understanding_result)
            elif intent_type == 'question_answer':
                return await self._handle_question_answer(user_input, understanding_result)
            elif intent_type == 'consultation':
                return await self._handle_consultation(user_input, understanding_result)
            elif intent_type == 'information_query':
                return await self._handle_information_query(user_input, understanding_result)
            else:
                return await self._handle_general_conversation(user_input, understanding_result)

        except Exception as e:
            self.logger.error(f"å¤„ç†å¯¹è¯æ„å›¾å¤±è´¥: {e}")
            return {
                'response_type': 'conversation',
                'message': 'æˆ‘ç†è§£æ‚¨çš„æ„æ€ï¼Œè®©æˆ‘æ¥å¸®åŠ©æ‚¨ã€‚',
                'data': {'intent': intent_type}
            }

    async def _handle_casual_chat(self, user_input: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é—²èŠ"""
        emotion = understanding_result.get('emotion_analysis', {}).get('emotion_type', 'neutral')

        chat_prompt = f"""
        ç”¨æˆ·è¯´ï¼š{user_input}
        æƒ…æ„Ÿç±»å‹ï¼š{emotion}

        è¯·ä»¥å‹å¥½ã€è‡ªç„¶çš„æ–¹å¼å›å¤ï¼Œä¿æŒå¯¹è¯çš„è¿è´¯æ€§ã€‚
        å›å¤è¦ç®€æ´ã€æ¸©æš–ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯ã€‚
        """

        response = await AgentFactory.ask_llm(chat_prompt)

        return {
            'response_type': 'conversation',
            'message': response.strip(),
            'data': {
                'intent': 'casual_chat',
                'emotion': emotion,
                'conversation_type': 'friendly_chat'
            }
        }

    async def _handle_question_answer(self, user_input: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é—®ç­”"""
        keywords = understanding_result.get('surface_analysis', {}).get('keywords', [])

        qa_prompt = f"""
        ç”¨æˆ·é—®é¢˜ï¼š{user_input}
        å…³é”®è¯ï¼š{', '.join(keywords)}

        è¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ç­”æ¡ˆã€‚å¦‚æœé—®é¢˜æ¶‰åŠä¸“ä¸šçŸ¥è¯†ï¼Œè¯·ç»™å‡ºè¯¦ç»†è§£é‡Šã€‚
        å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®è¯´æ˜å¹¶æä¾›å¯èƒ½çš„æ–¹å‘ã€‚
        """

        response = await AgentFactory.ask_llm(qa_prompt)

        return {
            'response_type': 'answer',
            'message': response.strip(),
            'data': {
                'intent': 'question_answer',
                'keywords': keywords,
                'answer_type': 'informative'
            }
        }

    async def _handle_consultation(self, user_input: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å’¨è¯¢å»ºè®®"""
        complexity = understanding_result.get('complexity_score', 0.5)

        consultation_prompt = f"""
        ç”¨æˆ·å’¨è¯¢ï¼š{user_input}
        å¤æ‚åº¦ï¼š{complexity}

        è¯·æä¾›ä¸“ä¸šã€å®ç”¨çš„å»ºè®®ã€‚è€ƒè™‘å¤šä¸ªè§’åº¦ï¼Œç»™å‡ºå…·ä½“å¯è¡Œçš„æ–¹æ¡ˆã€‚
        å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½ç»™å‡ºå‡†ç¡®å»ºè®®ï¼Œè¯·è¯´æ˜éœ€è¦äº†è§£å“ªäº›æ–¹é¢ã€‚
        """

        response = await AgentFactory.ask_llm(consultation_prompt)

        return {
            'response_type': 'consultation',
            'message': response.strip(),
            'data': {
                'intent': 'consultation',
                'complexity': complexity,
                'advice_type': 'professional'
            }
        }

    async def _handle_information_query(self, user_input: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä¿¡æ¯æŸ¥è¯¢"""
        entities = understanding_result.get('surface_analysis', {}).get('entities', [])

        query_prompt = f"""
        ç”¨æˆ·æŸ¥è¯¢ï¼š{user_input}
        ç›¸å…³å®ä½“ï¼š{', '.join(entities)}

        è¯·æä¾›ç›¸å…³ä¿¡æ¯ã€‚å¦‚æœæ˜¯å…·ä½“çš„äº‹å®æŸ¥è¯¢ï¼Œè¯·ç»™å‡ºå‡†ç¡®ä¿¡æ¯ã€‚
        å¦‚æœæ˜¯æ¦‚å¿µè§£é‡Šï¼Œè¯·ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è¯´æ˜ã€‚
        """

        response = await AgentFactory.ask_llm(query_prompt)

        return {
            'response_type': 'information',
            'message': response.strip(),
            'data': {
                'intent': 'information_query',
                'entities': entities,
                'query_type': 'factual'
            }
        }

    async def _handle_general_conversation(self, user_input: str, understanding_result: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ä¸€èˆ¬å¯¹è¯"""
        return {
            'response_type': 'conversation',
            'message': 'æˆ‘ç†è§£æ‚¨çš„æ„æ€ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©æ‚¨çš„å—ï¼Ÿ',
            'data': {
                'intent': 'general',
                'conversation_type': 'open'
            }
        }
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.copy()
    
    def clear_conversation_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
        self.logger.info("ğŸ—‘ï¸ [IntelligentPlanner] å¯¹è¯å†å²å·²æ¸…ç©º")

    async def _get_memory_context(self, user_input: str) -> Dict[str, Any]:
        """è·å–è®°å¿†ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        memory_context = {
            'user_preferences': self.user_preferences,
            'recent_patterns': self._get_recent_task_patterns(),
            'context_keywords': self.context_keywords[-10:],  # æœ€è¿‘10ä¸ªå…³é”®è¯
            'session_summary': self.session_summary
        }

        # æ£€æµ‹ä¸Šä¸‹æ–‡å¼•ç”¨
        context_references = await self._detect_context_references(user_input)
        if context_references:
            memory_context['references'] = context_references

        return memory_context

    async def _update_memory_system(self, user_input: str, understanding_result: Dict[str, Any]):
        """æ›´æ–°è®°å¿†ç³»ç»Ÿ"""
        try:
            # 1. æå–å¹¶æ›´æ–°ç”¨æˆ·åå¥½
            await self._extract_user_preferences(user_input, understanding_result)

            # 2. è®°å½•ä»»åŠ¡æ¨¡å¼
            await self._record_task_pattern(user_input, understanding_result)

            # 3. æ›´æ–°ä¸Šä¸‹æ–‡å…³é”®è¯
            await self._update_context_keywords(user_input)

            # 4. æ›´æ–°ä¼šè¯æ‘˜è¦
            await self._update_session_summary(user_input, understanding_result)

        except Exception as e:
            self.logger.error(f"æ›´æ–°è®°å¿†ç³»ç»Ÿå¤±è´¥: {e}")

    async def _detect_context_references(self, user_input: str) -> List[Dict[str, Any]]:
        """æ£€æµ‹ä¸Šä¸‹æ–‡å¼•ç”¨"""
        references = []

        # æ£€æµ‹æŒ‡ä»£è¯
        pronouns = ['è¿™ä¸ª', 'é‚£ä¸ª', 'å®ƒ', 'è¿™', 'é‚£', 'ä¸Šé¢çš„', 'å‰é¢çš„', 'åˆšæ‰çš„']
        for pronoun in pronouns:
            if pronoun in user_input:
                # æŸ¥æ‰¾æœ€è¿‘ç›¸å…³çš„å†…å®¹
                recent_content = self._find_recent_relevant_content(pronoun)
                if recent_content:
                    references.append({
                        'type': 'pronoun_reference',
                        'pronoun': pronoun,
                        'refers_to': recent_content
                    })

        # æ£€æµ‹ä»»åŠ¡å»¶ç»­
        continuation_words = ['ç»§ç»­', 'æ¥ç€', 'ç„¶å', 'ä¸‹ä¸€æ­¥', 'åŸºäºæ­¤']
        for word in continuation_words:
            if word in user_input:
                last_task = self._get_last_task_context()
                if last_task:
                    references.append({
                        'type': 'task_continuation',
                        'keyword': word,
                        'previous_task': last_task
                    })

        return references

    def _find_recent_relevant_content(self, pronoun: str) -> Optional[Dict[str, Any]]:
        """æŸ¥æ‰¾æœ€è¿‘ç›¸å…³çš„å†…å®¹"""
        # ä»æœ€è¿‘çš„å¯¹è¯ä¸­æŸ¥æ‰¾å¯èƒ½è¢«å¼•ç”¨çš„å†…å®¹
        for i in range(len(self.conversation_history) - 1, -1, -1):
            entry = self.conversation_history[i]
            if entry['role'] == 'assistant' and isinstance(entry['content'], dict):
                if 'steps' in entry['content']:
                    return {
                        'type': 'task_steps',
                        'content': entry['content']['steps'][:3],  # å‰3ä¸ªæ­¥éª¤
                        'timestamp': entry['timestamp']
                    }
        return None

    def _get_last_task_context(self) -> Optional[Dict[str, Any]]:
        """è·å–æœ€åä¸€ä¸ªä»»åŠ¡çš„ä¸Šä¸‹æ–‡"""
        for i in range(len(self.conversation_history) - 1, -1, -1):
            entry = self.conversation_history[i]
            if entry['role'] == 'assistant' and isinstance(entry['content'], dict):
                if entry['content'].get('response_type') == 'execution_plan':
                    return {
                        'task_type': entry['content'].get('understanding', {}).get('intent_analysis', {}).get('primary_intent'),
                        'steps_count': len(entry['content'].get('steps', [])),
                        'timestamp': entry['timestamp']
                    }
        return None

    async def _extract_user_preferences(self, user_input: str, understanding_result: Dict[str, Any]):
        """æå–å¹¶æ›´æ–°ç”¨æˆ·åå¥½"""
        try:
            # æå–åå¥½çš„æç¤ºè¯
            preference_prompt = f"""
            ä»ä»¥ä¸‹ç”¨æˆ·è¾“å…¥ä¸­æå–ç”¨æˆ·åå¥½ä¿¡æ¯ï¼š

            ç”¨æˆ·è¾“å…¥ï¼š{user_input}
            æ„å›¾åˆ†æï¼š{understanding_result.get('intent_analysis', {})}

            è¯·è¯†åˆ«ä»¥ä¸‹ç±»å‹çš„åå¥½ï¼š
            1. å·¥ä½œé£æ ¼åå¥½ï¼ˆè¯¦ç»†/ç®€æ´ã€å¿«é€Ÿ/ä»”ç»†ç­‰ï¼‰
            2. è¾“å‡ºæ ¼å¼åå¥½ï¼ˆå›¾è¡¨/æ–‡å­—ã€æ­¥éª¤æ•°é‡ç­‰ï¼‰
            3. å·¥å…·åå¥½ï¼ˆç‰¹å®šè½¯ä»¶ã€å¹³å°ç­‰ï¼‰
            4. è´¨é‡è¦æ±‚åå¥½ï¼ˆé«˜è´¨é‡/å¿«é€Ÿå®Œæˆç­‰ï¼‰

            å¦‚æœæ²¡æœ‰æ˜æ˜¾åå¥½ï¼Œè¿”å›ç©ºå­—å…¸ã€‚
            è¿”å›JSONæ ¼å¼ï¼š{{"preference_type": "preference_value"}}
            """

            response = await AgentFactory.ask_llm(preference_prompt)

            # å°è¯•è§£æJSON
            import json
            try:
                preferences = json.loads(response)
                if isinstance(preferences, dict):
                    # æ›´æ–°ç”¨æˆ·åå¥½
                    for key, value in preferences.items():
                        self.user_preferences[key] = value
                        self.logger.debug(f"æ›´æ–°ç”¨æˆ·åå¥½: {key} = {value}")
            except json.JSONDecodeError:
                pass

        except Exception as e:
            self.logger.error(f"æå–ç”¨æˆ·åå¥½å¤±è´¥: {e}")

    async def _record_task_pattern(self, user_input: str, understanding_result: Dict[str, Any]):
        """è®°å½•ä»»åŠ¡æ¨¡å¼"""
        try:
            intent = understanding_result.get('intent_analysis', {}).get('primary_intent', 'unknown')

            if intent not in self.task_patterns:
                self.task_patterns[intent] = {
                    'count': 0,
                    'common_keywords': [],
                    'typical_complexity': 'medium',
                    'last_seen': datetime.now().isoformat()
                }

            # æ›´æ–°æ¨¡å¼ä¿¡æ¯
            self.task_patterns[intent]['count'] += 1
            self.task_patterns[intent]['last_seen'] = datetime.now().isoformat()

            # æå–å…³é”®è¯
            keywords = user_input.lower().split()
            for keyword in keywords:
                if len(keyword) > 2 and keyword not in self.task_patterns[intent]['common_keywords']:
                    self.task_patterns[intent]['common_keywords'].append(keyword)

            # ä¿æŒå…³é”®è¯æ•°é‡åœ¨åˆç†èŒƒå›´
            if len(self.task_patterns[intent]['common_keywords']) > 10:
                self.task_patterns[intent]['common_keywords'] = self.task_patterns[intent]['common_keywords'][-10:]

        except Exception as e:
            self.logger.error(f"è®°å½•ä»»åŠ¡æ¨¡å¼å¤±è´¥: {e}")

    async def _update_context_keywords(self, user_input: str):
        """æ›´æ–°ä¸Šä¸‹æ–‡å…³é”®è¯"""
        try:
            # æå–å…³é”®è¯çš„ç®€å•å®ç°
            import re
            words = re.findall(r'\b\w{2,}\b', user_input.lower())

            # è¿‡æ»¤å¸¸è§è¯æ±‡
            stop_words = {'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'å¦‚æœ', 'å› ä¸º', 'æ‰€ä»¥'}
            keywords = [word for word in words if word not in stop_words and len(word) > 1]

            # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡å…³é”®è¯
            self.context_keywords.extend(keywords)

            # ä¿æŒå…³é”®è¯æ•°é‡åœ¨åˆç†èŒƒå›´
            if len(self.context_keywords) > 50:
                self.context_keywords = self.context_keywords[-50:]

        except Exception as e:
            self.logger.error(f"æ›´æ–°ä¸Šä¸‹æ–‡å…³é”®è¯å¤±è´¥: {e}")

    async def _update_session_summary(self, user_input: str, understanding_result: Dict[str, Any]):
        """æ›´æ–°ä¼šè¯æ‘˜è¦"""
        try:
            if len(self.conversation_history) % 5 == 0:  # æ¯5è½®å¯¹è¯æ›´æ–°ä¸€æ¬¡æ‘˜è¦
                summary_prompt = f"""
                åŸºäºä»¥ä¸‹å¯¹è¯å†å²ï¼Œç”Ÿæˆç®€æ´çš„ä¼šè¯æ‘˜è¦ï¼š

                å½“å‰æ‘˜è¦ï¼š{self.session_summary}
                æœ€æ–°ç”¨æˆ·è¾“å…¥ï¼š{user_input}
                ä¸»è¦æ„å›¾ï¼š{understanding_result.get('intent_analysis', {}).get('primary_intent')}

                è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼ŒåŒ…å«ï¼š
                1. ç”¨æˆ·çš„ä¸»è¦éœ€æ±‚ç±»å‹
                2. è®¨è®ºçš„å…³é”®è¯é¢˜
                3. ç”¨æˆ·çš„åå¥½ç‰¹ç‚¹

                åªè¿”å›æ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
                """

                response = await AgentFactory.ask_llm(summary_prompt)
                self.session_summary = response.strip()
                self.logger.debug(f"æ›´æ–°ä¼šè¯æ‘˜è¦: {self.session_summary}")

        except Exception as e:
            self.logger.error(f"æ›´æ–°ä¼šè¯æ‘˜è¦å¤±è´¥: {e}")

    def _get_recent_task_patterns(self) -> Dict[str, Any]:
        """è·å–æœ€è¿‘çš„ä»»åŠ¡æ¨¡å¼"""
        # è¿”å›æœ€è¿‘ä½¿ç”¨çš„ä»»åŠ¡æ¨¡å¼
        recent_patterns = {}
        for intent, pattern in self.task_patterns.items():
            if pattern['count'] > 0:
                recent_patterns[intent] = {
                    'count': pattern['count'],
                    'keywords': pattern['common_keywords'][-5:],  # æœ€è¿‘5ä¸ªå…³é”®è¯
                    'last_seen': pattern['last_seen']
                }
        return recent_patterns

    def get_memory_summary(self) -> Dict[str, Any]:
        """è·å–è®°å¿†ç³»ç»Ÿæ‘˜è¦"""
        return {
            'conversation_turns': len(self.conversation_history),
            'user_preferences': self.user_preferences,
            'task_patterns': self._get_recent_task_patterns(),
            'context_keywords_count': len(self.context_keywords),
            'session_summary': self.session_summary,
            'memory_updated': datetime.now().isoformat()
        }


# å·¥å‚å‡½æ•°
def create_intelligent_planner() -> IntelligentPlanner:
    """åˆ›å»ºæ™ºèƒ½è§„åˆ’å™¨å®ä¾‹"""
    return IntelligentPlanner()


# ä¾¿æ·å‡½æ•°
async def plan_user_request(user_input: str, context: Optional[Dict] = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè§„åˆ’ç”¨æˆ·è¯·æ±‚"""
    planner = create_intelligent_planner()
    return await planner.process_user_request(user_input, context)
