#!/usr/bin/env python3
"""
æ„å›¾æ£€æµ‹å®æ—¶ç›‘æ§ç³»ç»Ÿ
å®æ—¶ç›‘æ§å‡†ç¡®åº¦ã€è‡ªåŠ¨è°ƒä¼˜ã€å¼‚å¸¸æ£€æµ‹
"""

import asyncio
import logging
import time
import json
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import deque, defaultdict
import threading
from enum import Enum

class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    accuracy_rate: float                    # å‡†ç¡®ç‡
    response_time: float                    # å“åº”æ—¶é—´
    confidence_calibration: float           # ç½®ä¿¡åº¦æ ¡å‡†
    user_satisfaction: float               # ç”¨æˆ·æ»¡æ„åº¦
    error_rate: float                      # é”™è¯¯ç‡
    throughput: float                      # ååé‡ (è¯·æ±‚/ç§’)
    
    timestamp: datetime
    sample_count: int

@dataclass
class Alert:
    """å‘Šè­¦ä¿¡æ¯"""
    level: AlertLevel
    message: str
    metric_name: str
    current_value: float
    threshold: float
    timestamp: datetime
    suggestion: str = ""

class RealTimeMonitor:
    """å®æ—¶ç›‘æ§å™¨"""
    
    def __init__(self, window_size: int = 100):
        self.logger = logging.getLogger(__name__)
        self.window_size = window_size
        
        # æ»‘åŠ¨çª—å£æ•°æ®
        self.accuracy_window = deque(maxlen=window_size)
        self.response_time_window = deque(maxlen=window_size)
        self.confidence_window = deque(maxlen=window_size)
        self.satisfaction_window = deque(maxlen=window_size)
        
        # è®¡æ•°å™¨
        self.total_requests = 0
        self.error_count = 0
        self.start_time = time.time()
        
        # å‘Šè­¦é˜ˆå€¼
        self.thresholds = {
            'accuracy_rate': 0.7,          # å‡†ç¡®ç‡ä½äº70%å‘Šè­¦
            'response_time': 2.0,          # å“åº”æ—¶é—´è¶…è¿‡2ç§’å‘Šè­¦
            'error_rate': 0.1,             # é”™è¯¯ç‡è¶…è¿‡10%å‘Šè­¦
            'confidence_calibration': 0.6, # ç½®ä¿¡åº¦æ ¡å‡†ä½äº60%å‘Šè­¦
            'user_satisfaction': 0.6       # ç”¨æˆ·æ»¡æ„åº¦ä½äº60%å‘Šè­¦
        }
        
        # å‘Šè­¦å›è°ƒ
        self.alert_callbacks: List[Callable[[Alert], None]] = []
        
        # ç›‘æ§çŠ¶æ€
        self.monitoring_active = False
        self.monitor_thread = None
    
    def add_alert_callback(self, callback: Callable[[Alert], None]):
        """æ·»åŠ å‘Šè­¦å›è°ƒå‡½æ•°"""
        self.alert_callbacks.append(callback)
    
    def record_detection(self, 
                        accuracy: float,
                        response_time: float,
                        confidence: float,
                        user_satisfaction: Optional[float] = None,
                        is_error: bool = False):
        """è®°å½•ä¸€æ¬¡æ£€æµ‹ç»“æœ"""
        
        self.total_requests += 1
        
        if is_error:
            self.error_count += 1
        else:
            self.accuracy_window.append(accuracy)
            self.response_time_window.append(response_time)
            self.confidence_window.append(confidence)
            
            if user_satisfaction is not None:
                self.satisfaction_window.append(user_satisfaction)
    
    def get_current_metrics(self) -> PerformanceMetrics:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        
        if not self.accuracy_window:
            return PerformanceMetrics(
                accuracy_rate=0.0,
                response_time=0.0,
                confidence_calibration=0.0,
                user_satisfaction=0.0,
                error_rate=0.0,
                throughput=0.0,
                timestamp=datetime.now(),
                sample_count=0
            )
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy_rate = sum(self.accuracy_window) / len(self.accuracy_window)
        avg_response_time = sum(self.response_time_window) / len(self.response_time_window)
        avg_confidence = sum(self.confidence_window) / len(self.confidence_window)
        
        # ç½®ä¿¡åº¦æ ¡å‡† (ç®€åŒ–è®¡ç®—)
        confidence_calibration = 1.0 - abs(avg_confidence - accuracy_rate)
        
        # ç”¨æˆ·æ»¡æ„åº¦
        if self.satisfaction_window:
            user_satisfaction = sum(self.satisfaction_window) / len(self.satisfaction_window)
        else:
            user_satisfaction = 0.8  # é»˜è®¤å€¼
        
        # é”™è¯¯ç‡
        error_rate = self.error_count / self.total_requests if self.total_requests > 0 else 0.0
        
        # ååé‡
        elapsed_time = time.time() - self.start_time
        throughput = self.total_requests / elapsed_time if elapsed_time > 0 else 0.0
        
        return PerformanceMetrics(
            accuracy_rate=accuracy_rate,
            response_time=avg_response_time,
            confidence_calibration=confidence_calibration,
            user_satisfaction=user_satisfaction,
            error_rate=error_rate,
            throughput=throughput,
            timestamp=datetime.now(),
            sample_count=len(self.accuracy_window)
        )
    
    def check_alerts(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        
        alerts = []
        
        # å‡†ç¡®ç‡å‘Šè­¦
        if metrics.accuracy_rate < self.thresholds['accuracy_rate']:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                message=f"æ„å›¾æ£€æµ‹å‡†ç¡®ç‡è¿‡ä½: {metrics.accuracy_rate:.2f}",
                metric_name="accuracy_rate",
                current_value=metrics.accuracy_rate,
                threshold=self.thresholds['accuracy_rate'],
                timestamp=datetime.now(),
                suggestion="å»ºè®®æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°"
            ))
        
        # å“åº”æ—¶é—´å‘Šè­¦
        if metrics.response_time > self.thresholds['response_time']:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                message=f"å“åº”æ—¶é—´è¿‡é•¿: {metrics.response_time:.2f}s",
                metric_name="response_time",
                current_value=metrics.response_time,
                threshold=self.thresholds['response_time'],
                timestamp=datetime.now(),
                suggestion="å»ºè®®ä¼˜åŒ–æ¨¡å‹æ¨ç†é€Ÿåº¦æˆ–å¢åŠ ç¼“å­˜"
            ))
        
        # é”™è¯¯ç‡å‘Šè­¦
        if metrics.error_rate > self.thresholds['error_rate']:
            alerts.append(Alert(
                level=AlertLevel.ERROR,
                message=f"é”™è¯¯ç‡è¿‡é«˜: {metrics.error_rate:.2f}",
                metric_name="error_rate",
                current_value=metrics.error_rate,
                threshold=self.thresholds['error_rate'],
                timestamp=datetime.now(),
                suggestion="å»ºè®®æ£€æŸ¥ç³»ç»Ÿç¨³å®šæ€§å’Œå¼‚å¸¸å¤„ç†"
            ))
        
        # ç½®ä¿¡åº¦æ ¡å‡†å‘Šè­¦
        if metrics.confidence_calibration < self.thresholds['confidence_calibration']:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                message=f"ç½®ä¿¡åº¦æ ¡å‡†ä¸å‡†ç¡®: {metrics.confidence_calibration:.2f}",
                metric_name="confidence_calibration",
                current_value=metrics.confidence_calibration,
                threshold=self.thresholds['confidence_calibration'],
                timestamp=datetime.now(),
                suggestion="å»ºè®®é‡æ–°æ ¡å‡†ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•"
            ))
        
        # ç”¨æˆ·æ»¡æ„åº¦å‘Šè­¦
        if metrics.user_satisfaction < self.thresholds['user_satisfaction']:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                message=f"ç”¨æˆ·æ»¡æ„åº¦è¿‡ä½: {metrics.user_satisfaction:.2f}",
                metric_name="user_satisfaction",
                current_value=metrics.user_satisfaction,
                threshold=self.thresholds['user_satisfaction'],
                timestamp=datetime.now(),
                suggestion="å»ºè®®åˆ†æç”¨æˆ·åé¦ˆå¹¶æ”¹è¿›æ£€æµ‹é€»è¾‘"
            ))
        
        # è§¦å‘å‘Šè­¦å›è°ƒ
        for alert in alerts:
            for callback in self.alert_callbacks:
                try:
                    callback(alert)
                except Exception as e:
                    self.logger.error(f"å‘Šè­¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
        
        return alerts
    
    def start_monitoring(self, check_interval: float = 30.0):
        """å¯åŠ¨ç›‘æ§"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        
        def monitor_loop():
            while self.monitoring_active:
                try:
                    metrics = self.get_current_metrics()
                    alerts = self.check_alerts(metrics)
                    
                    if alerts:
                        self.logger.warning(f"æ£€æµ‹åˆ° {len(alerts)} ä¸ªå‘Šè­¦")
                    
                    time.sleep(check_interval)
                    
                except Exception as e:
                    self.logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(check_interval)
        
        self.monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        self.logger.info("ğŸ” å®æ—¶ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        
        self.logger.info("â¹ï¸ å®æ—¶ç›‘æ§å·²åœæ­¢")

class AdaptiveOptimizer:
    """è‡ªé€‚åº”ä¼˜åŒ–å™¨"""
    
    def __init__(self, monitor: RealTimeMonitor):
        self.monitor = monitor
        self.logger = logging.getLogger(__name__)
        
        # ä¼˜åŒ–å†å²
        self.optimization_history = []
        
        # ä¼˜åŒ–ç­–ç•¥
        self.strategies = {
            'low_accuracy': self._optimize_for_accuracy,
            'slow_response': self._optimize_for_speed,
            'poor_calibration': self._optimize_calibration
        }
    
    async def auto_optimize(self) -> Dict[str, Any]:
        """è‡ªåŠ¨ä¼˜åŒ–"""
        
        metrics = self.monitor.get_current_metrics()
        optimizations = []
        
        # æ ¹æ®æŒ‡æ ‡é€‰æ‹©ä¼˜åŒ–ç­–ç•¥
        if metrics.accuracy_rate < 0.7:
            result = await self._optimize_for_accuracy(metrics)
            optimizations.append(result)
        
        if metrics.response_time > 2.0:
            result = await self._optimize_for_speed(metrics)
            optimizations.append(result)
        
        if metrics.confidence_calibration < 0.6:
            result = await self._optimize_calibration(metrics)
            optimizations.append(result)
        
        # è®°å½•ä¼˜åŒ–å†å²
        optimization_record = {
            'timestamp': datetime.now(),
            'metrics_before': metrics,
            'optimizations_applied': optimizations
        }
        self.optimization_history.append(optimization_record)
        
        return {
            'optimizations_count': len(optimizations),
            'optimizations': optimizations,
            'metrics': metrics
        }
    
    async def _optimize_for_accuracy(self, metrics: PerformanceMetrics) -> Dict[str, Any]:
        """ä¼˜åŒ–å‡†ç¡®ç‡"""
        
        suggestions = []
        
        if metrics.accuracy_rate < 0.5:
            suggestions.extend([
                "å¢åŠ æœ¬åœ°æ£€æµ‹çš„å…³é”®è¯æ¨¡å¼",
                "è°ƒæ•´äº‘ç«¯æ¨¡å‹çš„æç¤ºè¯",
                "å¢åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æƒé‡"
            ])
        elif metrics.accuracy_rate < 0.7:
            suggestions.extend([
                "ä¼˜åŒ–æ„å›¾åˆ†ç±»é˜ˆå€¼",
                "å¢åŠ äº¤å‰éªŒè¯æ£€æµ‹å™¨",
                "æ”¹è¿›ç”¨æˆ·åé¦ˆæ”¶é›†"
            ])
        
        self.logger.info(f"ğŸ¯ å‡†ç¡®ç‡ä¼˜åŒ–å»ºè®®: {suggestions}")
        
        return {
            'strategy': 'accuracy_optimization',
            'current_accuracy': metrics.accuracy_rate,
            'suggestions': suggestions,
            'priority': 'high' if metrics.accuracy_rate < 0.5 else 'medium'
        }
    
    async def _optimize_for_speed(self, metrics: PerformanceMetrics) -> Dict[str, Any]:
        """ä¼˜åŒ–å“åº”é€Ÿåº¦"""
        
        suggestions = []
        
        if metrics.response_time > 5.0:
            suggestions.extend([
                "å¢åŠ æœ¬åœ°æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼",
                "å‡å°‘äº‘ç«¯APIè°ƒç”¨",
                "å®ç°ç»“æœç¼“å­˜æœºåˆ¶"
            ])
        elif metrics.response_time > 2.0:
            suggestions.extend([
                "ä¼˜åŒ–äº‘ç«¯APIè¶…æ—¶è®¾ç½®",
                "å¹¶è¡Œæ‰§è¡Œæœ¬åœ°å’Œäº‘ç«¯æ£€æµ‹",
                "é¢„åŠ è½½å¸¸ç”¨æ¨¡å¼"
            ])
        
        self.logger.info(f"âš¡ é€Ÿåº¦ä¼˜åŒ–å»ºè®®: {suggestions}")
        
        return {
            'strategy': 'speed_optimization',
            'current_response_time': metrics.response_time,
            'suggestions': suggestions,
            'priority': 'high' if metrics.response_time > 5.0 else 'medium'
        }
    
    async def _optimize_calibration(self, metrics: PerformanceMetrics) -> Dict[str, Any]:
        """ä¼˜åŒ–ç½®ä¿¡åº¦æ ¡å‡†"""
        
        suggestions = [
            "é‡æ–°æ ¡å‡†ç½®ä¿¡åº¦è®¡ç®—å…¬å¼",
            "å¢åŠ ç½®ä¿¡åº¦éªŒè¯æ ·æœ¬",
            "è°ƒæ•´æœ¬åœ°å’Œäº‘ç«¯ç»“æœèåˆæƒé‡"
        ]
        
        self.logger.info(f"ğŸ“Š æ ¡å‡†ä¼˜åŒ–å»ºè®®: {suggestions}")
        
        return {
            'strategy': 'calibration_optimization',
            'current_calibration': metrics.confidence_calibration,
            'suggestions': suggestions,
            'priority': 'medium'
        }

class IntentMonitoringSystem:
    """æ„å›¾æ£€æµ‹ç›‘æ§ç³»ç»Ÿ - ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.monitor = RealTimeMonitor()
        self.optimizer = AdaptiveOptimizer(self.monitor)
        
        # è®¾ç½®å‘Šè­¦å›è°ƒ
        self.monitor.add_alert_callback(self._handle_alert)
        
        # ç›‘æ§çŠ¶æ€
        self.system_active = False
    
    def _handle_alert(self, alert: Alert):
        """å¤„ç†å‘Šè­¦"""
        level_emoji = {
            AlertLevel.INFO: "â„¹ï¸",
            AlertLevel.WARNING: "âš ï¸", 
            AlertLevel.ERROR: "âŒ",
            AlertLevel.CRITICAL: "ğŸš¨"
        }
        
        emoji = level_emoji.get(alert.level, "ğŸ“¢")
        
        self.logger.warning(
            f"{emoji} [{alert.level.value.upper()}] {alert.message} "
            f"(å½“å‰å€¼: {alert.current_value:.2f}, é˜ˆå€¼: {alert.threshold:.2f})"
        )
        
        if alert.suggestion:
            self.logger.info(f"ğŸ’¡ å»ºè®®: {alert.suggestion}")
    
    async def record_detection_result(self,
                                    session_id: str,
                                    detection_result: Dict[str, Any],
                                    response_time: float,
                                    user_feedback: Optional[Dict[str, Any]] = None,
                                    is_error: bool = False):
        """è®°å½•æ£€æµ‹ç»“æœ"""
        
        # æå–æŒ‡æ ‡
        confidence = detection_result.get('confidence', 0.5)
        
        # ç®€åŒ–çš„å‡†ç¡®ç‡è®¡ç®— (å®é™…åº”è¯¥åŸºäºç”¨æˆ·åé¦ˆ)
        if user_feedback:
            accuracy = 1.0 if user_feedback.get('correct', False) else 0.0
            satisfaction = user_feedback.get('satisfaction', 0.8)
        else:
            accuracy = confidence  # ä¸´æ—¶ä½¿ç”¨ç½®ä¿¡åº¦ä½œä¸ºå‡†ç¡®ç‡
            satisfaction = None
        
        # è®°å½•åˆ°ç›‘æ§å™¨
        self.monitor.record_detection(
            accuracy=accuracy,
            response_time=response_time,
            confidence=confidence,
            user_satisfaction=satisfaction,
            is_error=is_error
        )
    
    async def get_dashboard_data(self) -> Dict[str, Any]:
        """è·å–ç›‘æ§é¢æ¿æ•°æ®"""
        
        metrics = self.monitor.get_current_metrics()
        
        return {
            'current_metrics': {
                'accuracy_rate': f"{metrics.accuracy_rate:.2%}",
                'response_time': f"{metrics.response_time:.2f}s",
                'confidence_calibration': f"{metrics.confidence_calibration:.2%}",
                'user_satisfaction': f"{metrics.user_satisfaction:.2%}",
                'error_rate': f"{metrics.error_rate:.2%}",
                'throughput': f"{metrics.throughput:.1f} req/s"
            },
            'sample_count': metrics.sample_count,
            'last_updated': metrics.timestamp.isoformat(),
            'system_status': 'active' if self.system_active else 'inactive',
            'thresholds': self.monitor.thresholds
        }
    
    def start_system(self):
        """å¯åŠ¨ç›‘æ§ç³»ç»Ÿ"""
        if not self.system_active:
            self.monitor.start_monitoring()
            self.system_active = True
            self.logger.info("ğŸš€ æ„å›¾æ£€æµ‹ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨")
    
    def stop_system(self):
        """åœæ­¢ç›‘æ§ç³»ç»Ÿ"""
        if self.system_active:
            self.monitor.stop_monitoring()
            self.system_active = False
            self.logger.info("â¹ï¸ æ„å›¾æ£€æµ‹ç›‘æ§ç³»ç»Ÿå·²åœæ­¢")

# å…¨å±€å®ä¾‹
_monitoring_system: Optional[IntentMonitoringSystem] = None

def get_monitoring_system() -> IntentMonitoringSystem:
    """è·å–ç›‘æ§ç³»ç»Ÿå®ä¾‹"""
    global _monitoring_system
    if _monitoring_system is None:
        _monitoring_system = IntentMonitoringSystem()
    return _monitoring_system
