"""
å¤æ‚æ¨ç†å¼•æ“
åŸºäºLangGraphæ‰©å±•TOTå¼•æ“ï¼Œå®ç°å› æœæ¨ç†ã€ç±»æ¯”æ¨ç†ã€é€»è¾‘æ¨ç†ç­‰å¤æ‚æ¨ç†èƒ½åŠ›
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple, Union
from dataclasses import dataclass
from enum import Enum
import json
from datetime import datetime

# å¯¼å…¥ç°æœ‰ç³»ç»Ÿç»„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from agent_system.agent_factory import AgentFactory
# TOTEngineå·²åˆ é™¤ï¼Œä½¿ç”¨ç®€åŒ–çš„æ¨ç†é€»è¾‘

# å°è¯•å¯¼å…¥LangGraph
try:
    from langgraph.graph import StateGraph
    from typing import TypedDict
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    logging.warning("LangGraph not available, using fallback reasoning")


class ReasoningType(Enum):
    """æ¨ç†ç±»å‹æšä¸¾"""
    CAUSAL = "causal"           # å› æœæ¨ç†
    ANALOGICAL = "analogical"   # ç±»æ¯”æ¨ç†
    LOGICAL = "logical"         # é€»è¾‘æ¨ç†
    ABDUCTIVE = "abductive"     # æº¯å› æ¨ç†
    INDUCTIVE = "inductive"     # å½’çº³æ¨ç†
    DEDUCTIVE = "deductive"     # æ¼”ç»æ¨ç†
    CREATIVE = "creative"       # åˆ›æ–°æ¨ç†


class ReasoningDepth(Enum):
    """æ¨ç†æ·±åº¦"""
    SHALLOW = 1    # æµ…å±‚æ¨ç†
    MEDIUM = 2     # ä¸­ç­‰æ¨ç†
    DEEP = 3       # æ·±åº¦æ¨ç†
    EXPERT = 4     # ä¸“å®¶çº§æ¨ç†


@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step_id: str
    reasoning_type: ReasoningType
    premise: str
    conclusion: str
    confidence: float
    evidence: List[str]
    timestamp: str


@dataclass
class ReasoningChain:
    """æ¨ç†é“¾"""
    chain_id: str
    steps: List[ReasoningStep]
    final_conclusion: str
    overall_confidence: float
    reasoning_path: List[str]


class ComplexReasoningEngine:
    """
    å¤æ‚æ¨ç†å¼•æ“
    
    å®ç°å¤šç§æ¨ç†æ¨¡å¼ï¼š
    1. å› æœæ¨ç†ï¼šåˆ†æåŸå› å’Œç»“æœçš„å…³ç³»
    2. ç±»æ¯”æ¨ç†ï¼šåŸºäºç›¸ä¼¼æ€§è¿›è¡Œæ¨ç†
    3. é€»è¾‘æ¨ç†ï¼šåŸºäºé€»è¾‘è§„åˆ™è¿›è¡Œæ¨ç†
    4. æº¯å› æ¨ç†ï¼šä»ç»“æœæ¨å¯¼åŸå› 
    5. å½’çº³æ¨ç†ï¼šä»ç‰¹æ®Šåˆ°ä¸€èˆ¬
    6. æ¼”ç»æ¨ç†ï¼šä»ä¸€èˆ¬åˆ°ç‰¹æ®Š
    7. åˆ›æ–°æ¨ç†ï¼šäº§ç”Ÿæ–°çš„è§è§£å’Œè§£å†³æ–¹æ¡ˆ
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.is_initialized = False
        self.reasoning_history = []
        self.knowledge_base = {}
        self.reasoning_patterns = {}
        
    async def initialize(self):
        """åˆå§‹åŒ–æ¨ç†å¼•æ“"""
        if self.is_initialized:
            return
            
        self.logger.info("ğŸ§  [ComplexReasoning] åˆå§‹åŒ–å¤æ‚æ¨ç†å¼•æ“...")
        
        try:
            # åˆå§‹åŒ–æ¨ç†æ¨¡å¼
            await self._initialize_reasoning_patterns()
            
            # åˆå§‹åŒ–çŸ¥è¯†åº“
            await self._initialize_knowledge_base()
            
            # TOTå¼•æ“å·²åˆ é™¤ï¼Œä½¿ç”¨ç®€åŒ–æ¨ç†
            
            self.is_initialized = True
            self.logger.info("âœ… [ComplexReasoning] å¤æ‚æ¨ç†å¼•æ“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ [ComplexReasoning] åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def process(self, request, analysis: Dict[str, Any], previous_results: Dict[str, Any], depth: int = 2) -> Dict[str, Any]:
        """å¤„ç†æ¨ç†è¯·æ±‚"""
        if not self.is_initialized:
            await self.initialize()
            
        self.logger.info(f"ğŸ§  [ComplexReasoning] å¼€å§‹å¤æ‚æ¨ç†ï¼Œæ·±åº¦: {depth}")
        
        try:
            # 1. åˆ†ææ¨ç†éœ€æ±‚
            reasoning_requirements = await self._analyze_reasoning_requirements(request, analysis)
            
            # 2. é€‰æ‹©æ¨ç†ç­–ç•¥
            reasoning_strategy = await self._select_reasoning_strategy(reasoning_requirements, depth)
            
            # 3. æ‰§è¡Œæ¨ç†
            reasoning_result = await self._execute_reasoning(request, reasoning_strategy, previous_results)
            
            # 4. éªŒè¯å’Œä¼˜åŒ–æ¨ç†ç»“æœ
            validated_result = await self._validate_reasoning(reasoning_result, request)
            
            return {
                'output': validated_result['conclusion'],
                'confidence': validated_result['confidence'],
                'reasoning_chain': validated_result['reasoning_chain'],
                'reasoning_trace': validated_result['reasoning_trace'],
                'metadata': {
                    'reasoning_types': reasoning_strategy['types'],
                    'depth': depth,
                    'strategy': reasoning_strategy
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ [ComplexReasoning] æ¨ç†å¤±è´¥: {e}")
            return await self._create_fallback_reasoning(request, str(e))
    
    async def _analyze_reasoning_requirements(self, request, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææ¨ç†éœ€æ±‚"""
        self.logger.debug("ğŸ” [ComplexReasoning] åˆ†ææ¨ç†éœ€æ±‚...")
        
        semantic_analysis = analysis.get('semantic_analysis', {})
        intent = semantic_analysis.get('intent_analysis', {}).get('primary_intent', 'unknown')
        complexity = semantic_analysis.get('complexity_score', 0.5)
        
        requirements = {
            'primary_reasoning_type': await self._determine_primary_reasoning_type(request.input_text, intent),
            'secondary_reasoning_types': await self._determine_secondary_reasoning_types(request.input_text, semantic_analysis),
            'requires_causal_analysis': await self._requires_causal_analysis(request.input_text),
            'requires_analogical_thinking': await self._requires_analogical_thinking(request.input_text),
            'requires_logical_validation': await self._requires_logical_validation(request.input_text),
            'complexity_level': complexity,
            'domain_knowledge_needed': await self._identify_domain_knowledge(request.input_text)
        }
        
        return requirements
    
    async def _select_reasoning_strategy(self, requirements: Dict[str, Any], depth: int) -> Dict[str, Any]:
        """é€‰æ‹©æ¨ç†ç­–ç•¥"""
        self.logger.debug("ğŸ¯ [ComplexReasoning] é€‰æ‹©æ¨ç†ç­–ç•¥...")
        
        strategy = {
            'types': [requirements['primary_reasoning_type']],
            'depth': depth,
            'parallel_reasoning': False,
            'use_langgraph': LANGGRAPH_AVAILABLE and depth >= 3,
            'use_tot': depth >= 2,
            'validation_steps': []
        }
        
        # æ·»åŠ æ¬¡è¦æ¨ç†ç±»å‹
        strategy['types'].extend(requirements['secondary_reasoning_types'])
        
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´ç­–ç•¥
        if requirements['complexity_level'] > 0.7:
            strategy['parallel_reasoning'] = True
            strategy['validation_steps'].append('logical_consistency')
            strategy['validation_steps'].append('evidence_support')
        
        # æ ¹æ®æ¨ç†ç±»å‹è°ƒæ•´ç­–ç•¥
        if requirements['requires_causal_analysis']:
            strategy['validation_steps'].append('causal_validation')
        
        if requirements['requires_analogical_thinking']:
            strategy['validation_steps'].append('analogy_validation')
        
        return strategy

    async def _execute_basic_reasoning(self, request, strategy: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºç¡€æ¨ç†å®ç°ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        self.logger.info("ğŸ”§ [ComplexReasoning] ä½¿ç”¨åŸºç¡€æ¨ç†æ¨¡å¼...")

        try:
            # è·å–è¯­ä¹‰åˆ†æç»“æœ
            semantic_result = previous_results.get('semantic', {})
            intent = semantic_result.get('intent_analysis', {}).get('primary_intent', 'unknown')
            keywords = semantic_result.get('surface_analysis', {}).get('keywords', [])

            # åŸºäºæ„å›¾è¿›è¡Œæ¨ç†
            reasoning_chain = []
            conclusion = ""

            if intent == 'question':
                reasoning_chain.append("è¯†åˆ«ä¸ºé—®é¢˜ç±»å‹ï¼Œéœ€è¦æä¾›è§£ç­”")
                if any(word in request.input_text.lower() for word in ['ä»€ä¹ˆæ˜¯', 'ä»€ä¹ˆå«', 'å®šä¹‰']):
                    reasoning_chain.append("è¿™æ˜¯æ¦‚å¿µå®šä¹‰ç±»é—®é¢˜")
                    conclusion = f"è¿™æ˜¯å…³äº{', '.join(keywords[:2]) if keywords else 'ç›¸å…³æ¦‚å¿µ'}çš„å®šä¹‰é—®é¢˜ã€‚æˆ‘å°†ä¸ºæ‚¨æä¾›è¯¦ç»†çš„è§£é‡Šå’Œç›¸å…³èƒŒæ™¯çŸ¥è¯†ã€‚"
                elif any(word in request.input_text.lower() for word in ['å¦‚ä½•', 'æ€ä¹ˆ', 'æ–¹æ³•']):
                    reasoning_chain.append("è¿™æ˜¯æ–¹æ³•è¯¢é—®ç±»é—®é¢˜")
                    conclusion = f"å…³äº{', '.join(keywords[:2]) if keywords else 'è¿™ä¸ªé—®é¢˜'}ï¼Œæˆ‘å»ºè®®é‡‡ç”¨ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥è§£å†³ã€‚é¦–å…ˆéœ€è¦åˆ†æå…·ä½“éœ€æ±‚ï¼Œç„¶ååˆ¶å®šè¯¦ç»†è®¡åˆ’ï¼Œæœ€åé€æ­¥å®æ–½ã€‚"
                elif any(word in request.input_text.lower() for word in ['ä¸ºä»€ä¹ˆ', 'åŸå› ']):
                    reasoning_chain.append("è¿™æ˜¯åŸå› åˆ†æç±»é—®é¢˜")
                    conclusion = f"å…³äº{', '.join(keywords[:2]) if keywords else 'è¿™ä¸ªç°è±¡'}çš„åŸå› ï¼Œéœ€è¦ä»å¤šä¸ªè§’åº¦è¿›è¡Œåˆ†æï¼ŒåŒ…æ‹¬æŠ€æœ¯å› ç´ ã€ç¯å¢ƒå› ç´ å’Œäººä¸ºå› ç´ ç­‰ã€‚"
                else:
                    conclusion = f"è¿™æ˜¯ä¸€ä¸ªå…³äº{', '.join(keywords[:3]) if keywords else 'ç›¸å…³ä¸»é¢˜'}çš„é—®é¢˜ã€‚è®©æˆ‘ä¸ºæ‚¨æä¾›å…¨é¢çš„åˆ†æå’Œè§£ç­”ã€‚"

            elif intent == 'request':
                reasoning_chain.append("è¯†åˆ«ä¸ºè¯·æ±‚ç±»å‹ï¼Œéœ€è¦æä¾›å¸®åŠ©")
                conclusion = f"æˆ‘ç†è§£æ‚¨çš„è¯·æ±‚ã€‚é’ˆå¯¹{', '.join(keywords[:2]) if keywords else 'æ‚¨çš„éœ€æ±‚'}ï¼Œæˆ‘å°†ä¸ºæ‚¨æä¾›æœ€åˆé€‚çš„è§£å†³æ–¹æ¡ˆå’Œå»ºè®®ã€‚"

            else:
                reasoning_chain.append("è¿›è¡Œé€šç”¨æ¨ç†åˆ†æ")
                conclusion = f"åŸºäºæ‚¨çš„è¾“å…¥ï¼Œæˆ‘åˆ†æè¿™æ¶‰åŠåˆ°{', '.join(keywords[:3]) if keywords else 'å¤šä¸ªæ–¹é¢'}ã€‚è®©æˆ‘ä¸ºæ‚¨æä¾›è¯¦ç»†çš„åˆ†æå’Œå»ºè®®ã€‚"

            return {
                'output': conclusion,
                'confidence': 0.7,
                'reasoning_chain': reasoning_chain,
                'reasoning_trace': [
                    {
                        'step': i+1,
                        'type': 'basic_reasoning',
                        'content': step,
                        'timestamp': datetime.now().isoformat()
                    } for i, step in enumerate(reasoning_chain)
                ],
                'metadata': {
                    'reasoning_type': 'basic',
                    'intent_based': True,
                    'keywords_used': keywords[:3]
                }
            }

        except Exception as e:
            self.logger.error(f"âŒ [ComplexReasoning] åŸºç¡€æ¨ç†å¤±è´¥: {e}")
            return {
                'output': "æˆ‘æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»ã€‚",
                'confidence': 0.3,
                'reasoning_chain': ["åŸºç¡€æ¨ç†å¤„ç†"],
                'reasoning_trace': [],
                'metadata': {'error': str(e)}
            }
    
    async def _execute_reasoning(self, request, strategy: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ¨ç†"""
        self.logger.info(f"âš¡ [ComplexReasoning] æ‰§è¡Œæ¨ç†ç­–ç•¥: {strategy['types']}")

        try:
            if strategy['use_langgraph'] and LANGGRAPH_AVAILABLE:
                return await self._execute_langgraph_reasoning(request, strategy, previous_results)
            elif strategy['use_tot']:
                return await self._execute_tot_reasoning(request, strategy, previous_results)
            else:
                return await self._execute_sequential_reasoning(request, strategy, previous_results)
        except Exception as e:
            self.logger.error(f"âŒ [ComplexReasoning] æ¨ç†æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›åŸºç¡€æ¨ç†ç»“æœ
            return await self._execute_basic_reasoning(request, strategy, previous_results)
    
    async def _execute_langgraph_reasoning(self, request, strategy: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨LangGraphæ‰§è¡Œå¤æ‚æ¨ç†"""
        self.logger.info("ğŸ”— [ComplexReasoning] ä½¿ç”¨LangGraphæ‰§è¡Œæ¨ç†...")
        
        # æ„å»ºæ¨ç†å›¾
        reasoning_graph = await self._build_reasoning_graph(strategy)
        
        # æ‰§è¡Œæ¨ç†å›¾
        initial_state = {
            'input': request.input_text,
            'context': request.context or {},
            'previous_results': previous_results,
            'reasoning_steps': [],
            'current_conclusion': '',
            'confidence': 0.0
        }
        
        try:
            final_state = await reasoning_graph.invoke(initial_state)
            
            return {
                'conclusion': final_state.get('current_conclusion', ''),
                'confidence': final_state.get('confidence', 0.0),
                'reasoning_steps': final_state.get('reasoning_steps', []),
                'reasoning_trace': final_state.get('reasoning_trace', [])
            }
        except Exception as e:
            self.logger.error(f"LangGraphæ¨ç†å¤±è´¥: {e}")
            return await self._execute_tot_reasoning(request, strategy, previous_results)
    
    async def _execute_tot_reasoning(self, request, strategy: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨TOTå¼•æ“æ‰§è¡Œæ¨ç†"""
        self.logger.info("ğŸŒ³ [ComplexReasoning] ä½¿ç”¨TOTå¼•æ“æ‰§è¡Œæ¨ç†...")
        
        # æ„å»ºTOTæ¨ç†ä¸Šä¸‹æ–‡
        context = await self._build_tot_context(request, strategy, previous_results)
        
        # ä½¿ç”¨ç®€åŒ–æ¨ç†æ›¿ä»£TOT
        simplified_result = await AgentFactory.ask_llm(
            f"è¯·å¯¹ä»¥ä¸‹é—®é¢˜è¿›è¡Œæ·±åº¦åˆ†æå’Œæ¨ç†ï¼š\n{request.input_text}\n\nä¸Šä¸‹æ–‡ï¼š{context}"
        )
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        return {
            'conclusion': simplified_result,
            'confidence': 0.7,  # ç®€åŒ–æ¨ç†ç½®ä¿¡åº¦
            'reasoning_steps': [{'step': 1, 'content': simplified_result}],
            'reasoning_trace': [
                {
                    'module': 'simplified_reasoning',
                    'action': 'analyze',
                    'result': simplified_result,
                    'timestamp': datetime.now().isoformat()
                }
            ]
        }
    
    async def _execute_sequential_reasoning(self, request, strategy: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé¡ºåºæ¨ç†"""
        self.logger.info("ğŸ“ [ComplexReasoning] æ‰§è¡Œé¡ºåºæ¨ç†...")
        
        reasoning_steps = []
        current_premise = request.input_text
        
        for reasoning_type in strategy['types']:
            step_result = await self._execute_single_reasoning_step(
                current_premise, reasoning_type, previous_results
            )
            reasoning_steps.append(step_result)
            current_premise = step_result['conclusion']
        
        # æ•´åˆæ¨ç†æ­¥éª¤
        final_conclusion = reasoning_steps[-1]['conclusion'] if reasoning_steps else "æ— æ³•å¾—å‡ºç»“è®º"
        overall_confidence = sum(step['confidence'] for step in reasoning_steps) / len(reasoning_steps) if reasoning_steps else 0.0
        
        return {
            'conclusion': final_conclusion,
            'confidence': overall_confidence,
            'reasoning_steps': reasoning_steps,
            'reasoning_trace': [
                {
                    'module': 'sequential_reasoning',
                    'action': 'execute_steps',
                    'result': {'steps_count': len(reasoning_steps)},
                    'timestamp': datetime.now().isoformat()
                }
            ]
        }
    
    async def _execute_single_reasoning_step(self, premise: str, reasoning_type: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•ä¸ªæ¨ç†æ­¥éª¤"""
        self.logger.debug(f"ğŸ” [ComplexReasoning] æ‰§è¡Œ{reasoning_type}æ¨ç†...")
        
        if reasoning_type == ReasoningType.CAUSAL.value:
            return await self._causal_reasoning(premise, context)
        elif reasoning_type == ReasoningType.ANALOGICAL.value:
            return await self._analogical_reasoning(premise, context)
        elif reasoning_type == ReasoningType.LOGICAL.value:
            return await self._logical_reasoning(premise, context)
        elif reasoning_type == ReasoningType.ABDUCTIVE.value:
            return await self._abductive_reasoning(premise, context)
        elif reasoning_type == ReasoningType.INDUCTIVE.value:
            return await self._inductive_reasoning(premise, context)
        elif reasoning_type == ReasoningType.DEDUCTIVE.value:
            return await self._deductive_reasoning(premise, context)
        elif reasoning_type == ReasoningType.CREATIVE.value:
            return await self._creative_reasoning(premise, context)
        else:
            return await self._default_reasoning(premise, context)
    
    async def _causal_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å› æœæ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œå› æœæ¨ç†åˆ†æï¼š

å‰æï¼š{premise}

è¯·åˆ†æï¼š
1. å¯èƒ½çš„åŸå› 
2. å¯èƒ½çš„ç»“æœ
3. å› æœå…³ç³»çš„å¼ºåº¦
4. æ”¯æŒè¯æ®

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""
        
        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'causes': ['æœªçŸ¥åŸå› '],
                'effects': ['æœªçŸ¥ç»“æœ'],
                'strength': 0.5,
                'evidence': []
            }
        
        return {
            'reasoning_type': ReasoningType.CAUSAL.value,
            'premise': premise,
            'conclusion': f"åŸºäºå› æœåˆ†æï¼š{result.get('effects', ['æœªçŸ¥'])[0]}",
            'confidence': result.get('strength', 0.5),
            'evidence': result.get('evidence', []),
            'details': result
        }
    
    async def _analogical_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """ç±»æ¯”æ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œç±»æ¯”æ¨ç†ï¼š

å½“å‰æƒ…å†µï¼š{premise}

è¯·æ‰¾å‡ºç›¸ä¼¼çš„æƒ…å†µæˆ–æ¡ˆä¾‹ï¼Œå¹¶è¿›è¡Œç±»æ¯”åˆ†æï¼š
1. ç›¸ä¼¼çš„æƒ…å†µ
2. ç›¸ä¼¼ç‚¹
3. ä¸åŒç‚¹
4. åŸºäºç±»æ¯”çš„æ¨è®º

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""
        
        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'analogies': ['ç±»ä¼¼æƒ…å†µ'],
                'similarities': ['ç›¸ä¼¼ç‚¹'],
                'differences': ['ä¸åŒç‚¹'],
                'conclusion': 'åŸºäºç±»æ¯”çš„æ¨è®º'
            }
        
        return {
            'reasoning_type': ReasoningType.ANALOGICAL.value,
            'premise': premise,
            'conclusion': result.get('conclusion', 'åŸºäºç±»æ¯”çš„æ¨è®º'),
            'confidence': 0.7,
            'evidence': result.get('analogies', []),
            'details': result
        }
    
    async def _logical_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """é€»è¾‘æ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œé€»è¾‘æ¨ç†ï¼š

å‰æï¼š{premise}

è¯·è¿›è¡Œä¸¥æ ¼çš„é€»è¾‘åˆ†æï¼š
1. è¯†åˆ«é€»è¾‘ç»“æ„
2. åº”ç”¨é€»è¾‘è§„åˆ™
3. å¾—å‡ºé€»è¾‘ç»“è®º
4. æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""
        
        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'logical_structure': 'ç®€å•å‘½é¢˜',
                'rules_applied': ['åŸºæœ¬é€»è¾‘'],
                'conclusion': 'é€»è¾‘ç»“è®º',
                'consistency': True
            }
        
        return {
            'reasoning_type': ReasoningType.LOGICAL.value,
            'premise': premise,
            'conclusion': result.get('conclusion', 'é€»è¾‘ç»“è®º'),
            'confidence': 0.9 if result.get('consistency', True) else 0.5,
            'evidence': result.get('rules_applied', []),
            'details': result
        }

    async def _abductive_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æº¯å› æ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œæº¯å› æ¨ç†ï¼ˆä»ç»“æœæ¨å¯¼æœ€å¯èƒ½çš„åŸå› ï¼‰ï¼š

è§‚å¯Ÿåˆ°çš„ç°è±¡ï¼š{premise}

è¯·åˆ†æï¼š
1. æœ€å¯èƒ½çš„è§£é‡Š
2. å…¶ä»–å¯èƒ½çš„è§£é‡Š
3. æ¯ç§è§£é‡Šçš„å¯èƒ½æ€§
4. æ”¯æŒè¯æ®

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""

        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'best_explanation': 'æœ€å¯èƒ½çš„è§£é‡Š',
                'alternative_explanations': ['å…¶ä»–è§£é‡Š'],
                'probabilities': [0.7, 0.3],
                'evidence': []
            }

        return {
            'reasoning_type': ReasoningType.ABDUCTIVE.value,
            'premise': premise,
            'conclusion': result.get('best_explanation', 'æœ€å¯èƒ½çš„è§£é‡Š'),
            'confidence': max(result.get('probabilities', [0.5])),
            'evidence': result.get('evidence', []),
            'details': result
        }

    async def _inductive_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å½’çº³æ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œå½’çº³æ¨ç†ï¼ˆä»ç‰¹æ®Šåˆ°ä¸€èˆ¬ï¼‰ï¼š

å…·ä½“æƒ…å†µï¼š{premise}

è¯·åˆ†æï¼š
1. è¯†åˆ«æ¨¡å¼å’Œè§„å¾‹
2. å½’çº³å‡ºä¸€èˆ¬æ€§ç»“è®º
3. è¯„ä¼°å½’çº³çš„å¯é æ€§
4. è€ƒè™‘ä¾‹å¤–æƒ…å†µ

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""

        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'patterns': ['è¯†åˆ«çš„æ¨¡å¼'],
                'general_conclusion': 'ä¸€èˆ¬æ€§ç»“è®º',
                'reliability': 0.6,
                'exceptions': []
            }

        return {
            'reasoning_type': ReasoningType.INDUCTIVE.value,
            'premise': premise,
            'conclusion': result.get('general_conclusion', 'ä¸€èˆ¬æ€§ç»“è®º'),
            'confidence': result.get('reliability', 0.6),
            'evidence': result.get('patterns', []),
            'details': result
        }

    async def _deductive_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ¼”ç»æ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œæ¼”ç»æ¨ç†ï¼ˆä»ä¸€èˆ¬åˆ°ç‰¹æ®Šï¼‰ï¼š

ä¸€èˆ¬æ€§å‰æï¼š{premise}

è¯·åˆ†æï¼š
1. è¯†åˆ«ä¸€èˆ¬æ€§è§„åˆ™
2. åº”ç”¨åˆ°å…·ä½“æƒ…å†µ
3. å¾—å‡ºç‰¹å®šç»“è®º
4. éªŒè¯æ¨ç†æœ‰æ•ˆæ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""

        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'general_rules': ['ä¸€èˆ¬è§„åˆ™'],
                'specific_application': 'å…·ä½“åº”ç”¨',
                'conclusion': 'ç‰¹å®šç»“è®º',
                'validity': True
            }

        return {
            'reasoning_type': ReasoningType.DEDUCTIVE.value,
            'premise': premise,
            'conclusion': result.get('conclusion', 'ç‰¹å®šç»“è®º'),
            'confidence': 0.9 if result.get('validity', True) else 0.5,
            'evidence': result.get('general_rules', []),
            'details': result
        }

    async def _creative_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›æ–°æ¨ç†"""
        prompt = f"""
è¯·è¿›è¡Œåˆ›æ–°æ¨ç†ï¼Œäº§ç”Ÿæ–°çš„è§è§£å’Œè§£å†³æ–¹æ¡ˆï¼š

é—®é¢˜æˆ–æƒ…å†µï¼š{premise}

è¯·è¿›è¡Œåˆ›æ–°æ€è€ƒï¼š
1. è·³å‡ºå¸¸è§„æ€ç»´
2. å¯»æ‰¾æ–°çš„è§’åº¦å’Œè§†è§’
3. äº§ç”Ÿåˆ›æ–°æ€§è§£å†³æ–¹æ¡ˆ
4. è¯„ä¼°åˆ›æ–°æ–¹æ¡ˆçš„å¯è¡Œæ€§

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""

        try:
            response = await AgentFactory.ask_llm(prompt)
            result = json.loads(response)
        except:
            result = {
                'new_perspectives': ['æ–°è§†è§’'],
                'innovative_solutions': ['åˆ›æ–°æ–¹æ¡ˆ'],
                'feasibility': 0.6,
                'novelty': 0.8
            }

        return {
            'reasoning_type': ReasoningType.CREATIVE.value,
            'premise': premise,
            'conclusion': result.get('innovative_solutions', ['åˆ›æ–°æ–¹æ¡ˆ'])[0],
            'confidence': result.get('feasibility', 0.6),
            'evidence': result.get('new_perspectives', []),
            'details': result
        }

    async def _default_reasoning(self, premise: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """é»˜è®¤æ¨ç†"""
        prompt = f"""
è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œåˆ†æå’Œæ¨ç†ï¼š

å†…å®¹ï¼š{premise}

è¯·æä¾›æ‚¨çš„åˆ†æå’Œç»“è®ºã€‚
"""

        try:
            response = await AgentFactory.ask_llm(prompt)
            conclusion = response.strip()
        except:
            conclusion = "åŸºäºåˆ†æçš„ç»“è®º"

        return {
            'reasoning_type': 'default',
            'premise': premise,
            'conclusion': conclusion,
            'confidence': 0.6,
            'evidence': [],
            'details': {}
        }

    # è¾…åŠ©æ–¹æ³•
    async def _determine_primary_reasoning_type(self, text: str, intent: str) -> str:
        """ç¡®å®šä¸»è¦æ¨ç†ç±»å‹"""
        # å…³é”®è¯åŒ¹é…
        if any(word in text for word in ['ä¸ºä»€ä¹ˆ', 'åŸå› ', 'å¯¼è‡´', 'å› ä¸º']):
            return ReasoningType.CAUSAL.value
        elif any(word in text for word in ['åƒ', 'ç±»ä¼¼', 'å¥½æ¯”', 'å¦‚åŒ']):
            return ReasoningType.ANALOGICAL.value
        elif any(word in text for word in ['å¦‚æœ', 'é‚£ä¹ˆ', 'é€»è¾‘', 'æ¨è®º']):
            return ReasoningType.LOGICAL.value
        elif any(word in text for word in ['åˆ›æ–°', 'æ–°çš„', 'ä¸åŒ', 'ç‹¬ç‰¹']):
            return ReasoningType.CREATIVE.value
        elif intent == 'question':
            return ReasoningType.ABDUCTIVE.value
        else:
            return ReasoningType.LOGICAL.value

    async def _determine_secondary_reasoning_types(self, text: str, semantic_analysis: Dict[str, Any]) -> List[str]:
        """ç¡®å®šæ¬¡è¦æ¨ç†ç±»å‹"""
        secondary_types = []

        # æ ¹æ®è¯­ä¹‰åˆ†æç¡®å®šæ¬¡è¦æ¨ç†ç±»å‹
        complexity = semantic_analysis.get('complexity_score', 0)

        if complexity > 0.7:
            secondary_types.append(ReasoningType.LOGICAL.value)

        if complexity > 0.8:
            secondary_types.append(ReasoningType.CREATIVE.value)

        return secondary_types

    async def _requires_causal_analysis(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å› æœåˆ†æ"""
        causal_keywords = ['ä¸ºä»€ä¹ˆ', 'åŸå› ', 'å¯¼è‡´', 'å› ä¸º', 'æ‰€ä»¥', 'ç»“æœ', 'å½±å“']
        return any(keyword in text for keyword in causal_keywords)

    async def _requires_analogical_thinking(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç±»æ¯”æ€ç»´"""
        analogy_keywords = ['åƒ', 'ç±»ä¼¼', 'å¥½æ¯”', 'å¦‚åŒ', 'ç›¸ä¼¼', 'å¯¹æ¯”', 'æ¯”è¾ƒ']
        return any(keyword in text for keyword in analogy_keywords)

    async def _requires_logical_validation(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é€»è¾‘éªŒè¯"""
        logic_keywords = ['é€»è¾‘', 'æ¨ç†', 'è¯æ˜', 'éªŒè¯', 'å¦‚æœ', 'é‚£ä¹ˆ', 'å› æ­¤']
        return any(keyword in text for keyword in logic_keywords)

    async def _identify_domain_knowledge(self, text: str) -> List[str]:
        """è¯†åˆ«éœ€è¦çš„é¢†åŸŸçŸ¥è¯†"""
        domains = []

        # ç®€å•çš„é¢†åŸŸè¯†åˆ«
        domain_keywords = {
            'technology': ['æŠ€æœ¯', 'è½¯ä»¶', 'ç¼–ç¨‹', 'è®¡ç®—æœº', 'AI', 'äººå·¥æ™ºèƒ½'],
            'science': ['ç§‘å­¦', 'ç‰©ç†', 'åŒ–å­¦', 'ç”Ÿç‰©', 'æ•°å­¦'],
            'business': ['å•†ä¸š', 'ç®¡ç†', 'è¥é”€', 'è´¢åŠ¡', 'ç»æµ'],
            'medicine': ['åŒ»å­¦', 'å¥åº·', 'ç–¾ç—…', 'æ²»ç–—', 'è¯ç‰©'],
            'education': ['æ•™è‚²', 'å­¦ä¹ ', 'æ•™å­¦', 'åŸ¹è®­', 'è¯¾ç¨‹']
        }

        for domain, keywords in domain_keywords.items():
            if any(keyword in text for keyword in keywords):
                domains.append(domain)

        return domains

    async def _build_reasoning_graph(self, strategy: Dict[str, Any]):
        """æ„å»ºæ¨ç†å›¾ï¼ˆLangGraphï¼‰"""
        if not LANGGRAPH_AVAILABLE:
            raise RuntimeError("LangGraph not available")

        graph = StateGraph()

        # å®šä¹‰æ¨ç†èŠ‚ç‚¹
        async def reasoning_node(state):
            reasoning_type = state.get('current_reasoning_type', 'logical')
            premise = state.get('current_premise', state['input'])

            step_result = await self._execute_single_reasoning_step(
                premise, reasoning_type, state.get('previous_results', {})
            )

            state['reasoning_steps'].append(step_result)
            state['current_conclusion'] = step_result['conclusion']
            state['confidence'] = step_result['confidence']

            return state

        # æ·»åŠ æ¨ç†èŠ‚ç‚¹
        for i, reasoning_type in enumerate(strategy['types']):
            node_name = f"reasoning_{i}_{reasoning_type}"
            graph.add_node(node_name, RunnableCallable(reasoning_node))

            if i > 0:
                prev_node = f"reasoning_{i-1}_{strategy['types'][i-1]}"
                graph.add_edge(prev_node, node_name)

        # è®¾ç½®å…¥å£ç‚¹
        if strategy['types']:
            entry_node = f"reasoning_0_{strategy['types'][0]}"
            graph.set_entry_point(entry_node)

        return graph.compile()

    async def _build_tot_context(self, request, strategy: Dict[str, Any], previous_results: Dict[str, Any]) -> str:
        """æ„å»ºTOTæ¨ç†ä¸Šä¸‹æ–‡"""
        context_parts = []

        # æ·»åŠ åŸºç¡€ä¸Šä¸‹æ–‡
        if request.context:
            context_parts.append(f"ä¸Šä¸‹æ–‡ï¼š{json.dumps(request.context, ensure_ascii=False)}")

        # æ·»åŠ æ¨ç†ç­–ç•¥ä¿¡æ¯
        context_parts.append(f"æ¨ç†ç±»å‹ï¼š{', '.join(strategy['types'])}")
        context_parts.append(f"æ¨ç†æ·±åº¦ï¼š{strategy['depth']}")

        # æ·»åŠ ä¹‹å‰çš„ç»“æœ
        if previous_results:
            context_parts.append(f"ä¹‹å‰çš„åˆ†æç»“æœï¼š{json.dumps(previous_results, ensure_ascii=False)}")

        return "\n".join(context_parts)

    async def _validate_reasoning(self, reasoning_result: Dict[str, Any], request) -> Dict[str, Any]:
        """éªŒè¯å’Œä¼˜åŒ–æ¨ç†ç»“æœ"""
        self.logger.debug("âœ… [ComplexReasoning] éªŒè¯æ¨ç†ç»“æœ...")

        # åŸºç¡€éªŒè¯
        if not reasoning_result.get('conclusion'):
            reasoning_result['conclusion'] = "æ— æ³•å¾—å‡ºæ˜ç¡®ç»“è®º"
            reasoning_result['confidence'] = 0.1

        # ç½®ä¿¡åº¦è°ƒæ•´
        if reasoning_result.get('confidence', 0) > 0.95:
            reasoning_result['confidence'] = 0.95  # é¿å…è¿‡åº¦è‡ªä¿¡

        # æ„å»ºæ¨ç†é“¾
        reasoning_chain = ReasoningChain(
            chain_id=f"chain_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            steps=[],  # è¿™é‡Œå¯ä»¥ä»reasoning_stepsæ„å»º
            final_conclusion=reasoning_result['conclusion'],
            overall_confidence=reasoning_result['confidence'],
            reasoning_path=[]
        )

        return {
            'conclusion': reasoning_result['conclusion'],
            'confidence': reasoning_result['confidence'],
            'reasoning_chain': reasoning_chain,
            'reasoning_trace': reasoning_result.get('reasoning_trace', [])
        }

    async def _create_fallback_reasoning(self, request, error_msg: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨æ¨ç†ç»“æœ"""
        return {
            'output': f"æ¨ç†è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š{error_msg}ã€‚æˆ‘å°†å°½åŠ›ä¸ºæ‚¨æä¾›åŸºç¡€åˆ†æã€‚",
            'confidence': 0.3,
            'reasoning_chain': None,
            'reasoning_trace': [
                {
                    'module': 'complex_reasoning',
                    'action': 'fallback',
                    'error': error_msg,
                    'timestamp': datetime.now().isoformat()
                }
            ],
            'metadata': {'error': True, 'fallback': True}
        }

    async def _initialize_reasoning_patterns(self):
        """åˆå§‹åŒ–æ¨ç†æ¨¡å¼"""
        self.reasoning_patterns = {
            'causal': {
                'keywords': ['ä¸ºä»€ä¹ˆ', 'åŸå› ', 'å¯¼è‡´', 'å› ä¸º', 'æ‰€ä»¥'],
                'templates': ['å¦‚æœ{A}ï¼Œé‚£ä¹ˆ{B}', 'ç”±äº{A}ï¼Œå¯¼è‡´{B}']
            },
            'analogical': {
                'keywords': ['åƒ', 'ç±»ä¼¼', 'å¥½æ¯”', 'å¦‚åŒ'],
                'templates': ['{A}å°±åƒ{B}ä¸€æ ·', '{A}å’Œ{B}ç›¸ä¼¼']
            },
            'logical': {
                'keywords': ['é€»è¾‘', 'æ¨ç†', 'å› æ­¤', 'æ‰€ä»¥'],
                'templates': ['æ ¹æ®{A}ï¼Œå¯ä»¥æ¨å‡º{B}', 'å¦‚æœ{A}ä¸ºçœŸï¼Œåˆ™{B}ä¸ºçœŸ']
            }
        }

    async def _initialize_knowledge_base(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        self.knowledge_base = {
            'common_sense': [],
            'domain_knowledge': {},
            'reasoning_rules': [],
            'case_studies': []
        }
