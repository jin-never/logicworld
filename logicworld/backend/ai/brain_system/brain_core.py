"""
æ™ºèƒ½å¤§è„‘æ ¸å¿ƒ - ç»Ÿä¸€åè°ƒæ¥å£
æ•´åˆæ‰€æœ‰æ™ºèƒ½æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€çš„å¤§è„‘æ¥å£å’Œåè°ƒæœºåˆ¶
"""

import logging
import asyncio
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass
from enum import Enum
import json
from datetime import datetime

# å¯¼å…¥ç°æœ‰ç³»ç»Ÿç»„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from agent_system.agent_factory import AgentFactory
from .mode_manager import mode_manager, ProcessingMode


class LegacyProcessingMode(Enum):
    """æ—§ç‰ˆå¤„ç†æ¨¡å¼æšä¸¾ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰"""
    SIMPLE = "simple"           # ç®€å•å¤„ç†
    SEMANTIC = "semantic"       # è¯­ä¹‰ç†è§£
    REASONING = "reasoning"     # å¤æ‚æ¨ç†
    COLLABORATIVE = "collaborative"  # å¤šä»£ç†åä½œ
    ADAPTIVE = "adaptive"       # è‡ªé€‚åº”å­¦ä¹ 


class ComplexityLevel(Enum):
    """å¤æ‚åº¦çº§åˆ«"""
    LOW = 1      # ç®€å•é—®ç­”
    MEDIUM = 2   # éœ€è¦æ¨ç†
    HIGH = 3     # å¤æ‚åˆ†æ
    EXPERT = 4   # ä¸“å®¶çº§åˆ«


@dataclass
class BrainRequest:
    """å¤§è„‘è¯·æ±‚æ•°æ®ç»“æ„"""
    input_text: str
    context: Dict[str, Any] = None
    user_id: str = "default"
    session_id: str = "default"
    mode: LegacyProcessingMode = LegacyProcessingMode.SEMANTIC
    complexity: ComplexityLevel = ComplexityLevel.MEDIUM
    metadata: Dict[str, Any] = None


@dataclass
class BrainResponse:
    """å¤§è„‘å“åº”æ•°æ®ç»“æ„"""
    output: str
    confidence: float
    processing_path: List[str]
    reasoning_trace: List[Dict[str, Any]]
    memory_updates: List[Dict[str, Any]]
    metadata: Dict[str, Any]
    timestamp: str


class IntelligentBrain:
    """
    æ™ºèƒ½å¤§è„‘æ ¸å¿ƒç±»
    
    ä½œä¸ºæ•´ä¸ªæ™ºèƒ½ç³»ç»Ÿçš„åè°ƒä¸­å¿ƒï¼Œè´Ÿè´£ï¼š
    1. åˆ†æè¾“å…¥å¤æ‚åº¦å’Œç±»å‹
    2. é€‰æ‹©åˆé€‚çš„å¤„ç†æ¨¡å¼å’Œæ¨¡å—
    3. åè°ƒå„ä¸ªæ™ºèƒ½æ¨¡å—çš„å·¥ä½œ
    4. æ•´åˆç»“æœå¹¶æä¾›ç»Ÿä¸€è¾“å‡º
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.modules = {}
        self.processing_history = []
        self.is_initialized = False
        
    async def initialize(self):
        """åˆå§‹åŒ–å¤§è„‘ç³»ç»Ÿ"""
        if self.is_initialized:
            return
            
        self.logger.info("ğŸ§  [IntelligentBrain] å¼€å§‹åˆå§‹åŒ–æ™ºèƒ½å¤§è„‘ç³»ç»Ÿ...")
        
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from .semantic_understanding import SemanticUnderstandingModule
            from .reasoning_engine import ComplexReasoningEngine
            from .memory_system import IntelligentMemorySystem
            from .multi_agent_framework import MultiAgentFramework
            from .adaptive_learning import AdaptiveLearningSystem
            from .ai_integration import IntelligentAIIntegration

            # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
            self.modules['semantic'] = SemanticUnderstandingModule()
            self.modules['reasoning'] = ComplexReasoningEngine()
            self.modules['memory'] = IntelligentMemorySystem()
            self.modules['agents'] = MultiAgentFramework()
            self.modules['learning'] = AdaptiveLearningSystem()
            self.modules['ai'] = IntelligentAIIntegration()
            
            # åˆå§‹åŒ–å„æ¨¡å—
            for name, module in self.modules.items():
                await module.initialize()
                self.logger.info(f"âœ… [IntelligentBrain] {name} æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
                
            self.is_initialized = True
            self.logger.info("ğŸ‰ [IntelligentBrain] æ™ºèƒ½å¤§è„‘ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ [IntelligentBrain] åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def process(self, request: Union[str, BrainRequest], user_preferred_mode: str = None) -> BrainResponse:
        """
        å¤„ç†è¾“å…¥è¯·æ±‚çš„ä¸»å…¥å£ï¼ˆæ”¯æŒæ™ºèƒ½æ¨¡å¼æ£€æµ‹ï¼‰

        Args:
            request: è¾“å…¥è¯·æ±‚ï¼ˆå­—ç¬¦ä¸²æˆ–BrainRequestå¯¹è±¡ï¼‰
            user_preferred_mode: ç”¨æˆ·æŒ‡å®šçš„å¤„ç†æ¨¡å¼ (daily/professional)

        Returns:
            BrainResponse: å¤„ç†ç»“æœ
        """
        if not self.is_initialized:
            await self.initialize()

        # æ ‡å‡†åŒ–è¯·æ±‚æ ¼å¼
        if isinstance(request, str):
            request = BrainRequest(input_text=request)

        # æ·»åŠ ç”¨æˆ·æŒ‡å®šæ¨¡å¼åˆ°ä¸Šä¸‹æ–‡
        if user_preferred_mode:
            if not hasattr(request, 'context') or request.context is None:
                request.context = {}
            request.context["user_preferred_mode"] = user_preferred_mode

        # ä¿å­˜å½“å‰è¯·æ±‚æ–‡æœ¬ä¾›AIæ¨¡å—ä½¿ç”¨
        self._current_request_text = request.input_text

        self.logger.info(f"ğŸ§  [IntelligentBrain] å¼€å§‹å¤„ç†è¯·æ±‚: {request.input_text[:100]}...")

        try:
            # 0. æ™ºèƒ½æ¨¡å¼æ£€æµ‹å’Œé€‰æ‹©
            await self._handle_intelligent_mode_selection(request, user_preferred_mode)

            # 1. åˆ†æè¾“å…¥å¤æ‚åº¦å’Œç±»å‹
            analysis = await self._analyze_input(request)

            # 2. é€‰æ‹©å¤„ç†ç­–ç•¥
            strategy = await self._select_strategy(request, analysis)

            # 3. æ‰§è¡Œå¤„ç†æµç¨‹
            result = await self._execute_strategy(request, strategy, analysis)

            # 4. åå¤„ç†å’Œå­¦ä¹ 
            response = await self._post_process(request, result, strategy)

            # 5. è®°å½•å¤„ç†å†å²
            self.processing_history.append({
                'request': request,
                'response': response,
                'timestamp': datetime.now().isoformat()
            })

            return response

        except Exception as e:
            self.logger.error(f"âŒ [IntelligentBrain] å¤„ç†å¤±è´¥: {e}")
            return BrainResponse(
                output=f"å¤„ç†å¤±è´¥: {str(e)}",
                confidence=0.0,
                processing_path=["error"],
                reasoning_trace=[{"error": str(e)}],
                memory_updates=[],
                metadata={"error": True},
                timestamp=datetime.now().isoformat()
            )

    async def _handle_intelligent_mode_selection(self, request: BrainRequest, user_preferred_mode: str = None):
        """å¤„ç†æ™ºèƒ½æ¨¡å¼æ£€æµ‹å’Œé€‰æ‹©"""

        try:
            # å¦‚æœæœ‰AIæ¨¡å—ï¼Œä½¿ç”¨æ™ºèƒ½æ¨¡å¼æ£€æµ‹
            if 'ai' in self.modules:
                ai_module = self.modules['ai']

                # æ£€æµ‹æœ€ä½³å¤„ç†æ¨¡å¼
                if user_preferred_mode:
                    # ç”¨æˆ·æŒ‡å®šæ¨¡å¼
                    processing_mode = user_preferred_mode
                    mode_confidence = 1.0
                    mode_reasoning = "ç”¨æˆ·æŒ‡å®šæ¨¡å¼"
                    detection_id = None
                    self.logger.info(f"ğŸ‘¤ [IntelligentBrain] ç”¨æˆ·æŒ‡å®šæ¨¡å¼: {processing_mode}")
                else:
                    # è‡ªåŠ¨æ£€æµ‹æ¨¡å¼
                    try:
                        # ä½¿ç”¨AIé›†æˆç³»ç»Ÿçš„æ¨¡å¼æ£€æµ‹æœåŠ¡
                        if hasattr(ai_module, 'mode_detection_service') and ai_module.mode_detection_service:
                            # ç¡®å®šæ£€æµ‹æ¨¡å¼ï¼šç”¨æˆ·æŒ‡å®š > è‡ªåŠ¨æ£€æµ‹
                            detection_mode = user_preferred_mode if user_preferred_mode else "auto"

                            mode_result = await ai_module.mode_detection_service.detect_user_mode(
                                request.input_text,
                                getattr(request, 'context', {}),
                                user_mode_preference=detection_mode
                            )

                            if mode_result["success"]:
                                processing_mode = mode_result["mode"]
                                mode_confidence = mode_result["confidence"]
                                mode_reasoning = mode_result["reasoning"]
                                detection_id = mode_result["detection_id"]
                                self.logger.info(f"ğŸ¯ [IntelligentBrain] æ£€æµ‹åˆ°æ¨¡å¼: {processing_mode} (ç½®ä¿¡åº¦: {mode_confidence:.2f})")
                            else:
                                processing_mode = "daily"
                                mode_confidence = 0.5
                                mode_reasoning = "æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼"
                                detection_id = None
                                self.logger.warning(f"âš ï¸ [IntelligentBrain] æ¨¡å¼æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼")
                        else:
                            processing_mode = "daily"
                            mode_confidence = 0.5
                            mode_reasoning = "æ¨¡å¼æ£€æµ‹æœåŠ¡æœªå¯ç”¨"
                            detection_id = None
                    except Exception as e:
                        processing_mode = "daily"
                        mode_confidence = 0.5
                        mode_reasoning = f"æ£€æµ‹å¼‚å¸¸: {str(e)}"
                        detection_id = None
                        self.logger.warning(f"âš ï¸ [IntelligentBrain] æ¨¡å¼æ£€æµ‹å¼‚å¸¸: {e}")

                # å°†æ¨¡å¼ä¿¡æ¯æ·»åŠ åˆ°è¯·æ±‚ä¸Šä¸‹æ–‡
                if not hasattr(request, 'context') or request.context is None:
                    request.context = {}

                request.context.update({
                    "processing_mode": processing_mode,
                    "mode_confidence": mode_confidence,
                    "mode_reasoning": mode_reasoning,
                    "detection_id": detection_id
                })

                # æ ¹æ®æ£€æµ‹æ¨¡å¼è°ƒæ•´ç³»ç»Ÿè¡Œä¸º
                if processing_mode == "professional":
                    # ä¸“ä¸šæ¨¡å¼ï¼šæ›´ä¸¥æ ¼ã€æ›´è¯¦ç»†çš„å¤„ç†
                    self.logger.info("ğŸ“ [IntelligentBrain] å¯ç”¨ä¸“ä¸šæ¨¡å¼å¤„ç†")
                else:
                    # æ—¥å¸¸æ¨¡å¼ï¼šæ›´è½»æ¾ã€æ›´å®ç”¨çš„å¤„ç†
                    self.logger.info("ğŸ“‹ [IntelligentBrain] å¯ç”¨æ—¥å¸¸æ¨¡å¼å¤„ç†")

            else:
                # æ²¡æœ‰AIæ¨¡å—ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼é€‰æ‹©
                suggested_mode = mode_manager.auto_select_mode(
                    request.input_text,
                    getattr(request, 'context', {})
                )

                if suggested_mode != mode_manager.get_current_mode():
                    mode_manager.switch_mode(suggested_mode)
                    self.logger.info(f"ğŸ”„ [IntelligentBrain] è‡ªåŠ¨åˆ‡æ¢åˆ°{suggested_mode.value}æ¨¡å¼")

        except Exception as e:
            self.logger.error(f"âŒ [IntelligentBrain] æ¨¡å¼é€‰æ‹©å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡å¼
            if not hasattr(request, 'context') or request.context is None:
                request.context = {}
            request.context.update({
                "processing_mode": "daily",
                "mode_confidence": 0.5,
                "mode_reasoning": f"æ¨¡å¼é€‰æ‹©å¤±è´¥: {str(e)}",
                "detection_id": None
            })

    async def _analyze_input(self, request: BrainRequest) -> Dict[str, Any]:
        """åˆ†æè¾“å…¥çš„å¤æ‚åº¦ã€ç±»å‹å’Œæ„å›¾"""
        self.logger.info("ğŸ” [IntelligentBrain] åˆ†æè¾“å…¥...")
        
        # ä½¿ç”¨è¯­ä¹‰ç†è§£æ¨¡å—è¿›è¡Œåˆæ­¥åˆ†æ
        semantic_analysis = await self.modules['semantic'].analyze_input(request.input_text)
        
        # å¤æ‚åº¦è¯„ä¼°
        complexity = await self._assess_complexity(request.input_text, semantic_analysis)
        
        # æ„å›¾è¯†åˆ«
        intent = await self._identify_intent(request.input_text, semantic_analysis)
        
        return {
            'semantic_analysis': semantic_analysis,
            'complexity': complexity.value,  # ä½¿ç”¨æšä¸¾çš„å€¼è€Œä¸æ˜¯æšä¸¾å¯¹è±¡
            'complexity_name': complexity.name,  # æ·»åŠ æšä¸¾åç§°
            'intent': intent,
            'requires_reasoning': complexity.value >= ComplexityLevel.MEDIUM.value,
            'requires_collaboration': complexity.value >= ComplexityLevel.HIGH.value,
            'requires_memory': True  # æ€»æ˜¯éœ€è¦è®°å¿†ç³»ç»Ÿ
        }
    
    async def _select_strategy(self, request: BrainRequest, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®åˆ†æç»“æœå’Œå½“å‰æ¨¡å¼é€‰æ‹©å¤„ç†ç­–ç•¥"""
        self.logger.info("ğŸ¯ [IntelligentBrain] é€‰æ‹©å¤„ç†ç­–ç•¥...")

        # è·å–å½“å‰æ¨¡å¼é…ç½®
        mode_config = mode_manager.get_current_config()
        current_mode = mode_manager.get_current_mode()

        strategy = {
            'mode': current_mode.value,
            'modules': ['semantic', 'memory', 'ai'],  # åŸºç¡€æ¨¡å—
            'parallel_processing': False,
            'reasoning_depth': 1,
            'ai_params': mode_manager.get_ai_params()
        }

        # æ ¹æ®æ¨¡å¼é…ç½®è°ƒæ•´ç­–ç•¥
        if mode_config.use_complex_reasoning and analysis['requires_reasoning']:
            strategy['modules'].append('reasoning')
            strategy['reasoning_depth'] = analysis['complexity'].value

        if mode_config.use_multi_agent and analysis['requires_collaboration']:
            strategy['modules'].append('agents')
            strategy['parallel_processing'] = True

        if mode_config.use_langgraph and analysis['complexity'] >= ComplexityLevel.HIGH.value:
            strategy['use_langgraph'] = True

        # æ€»æ˜¯åŒ…å«å­¦ä¹ æ¨¡å—
        strategy['modules'].append('learning')

        self.logger.info(f"ğŸ¯ [IntelligentBrain] ç­–ç•¥é…ç½®: {current_mode.value}æ¨¡å¼, æ¨¡å—: {strategy['modules']}")

        return strategy
    
    async def _execute_strategy(self, request: BrainRequest, strategy: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œé€‰å®šçš„å¤„ç†ç­–ç•¥"""
        self.logger.info(f"âš¡ [IntelligentBrain] æ‰§è¡Œç­–ç•¥: {strategy['modules']}")
        
        results = {}
        processing_path = []
        
        # é¡ºåºå¤„ç†åŸºç¡€æ¨¡å—
        for module_name in ['semantic', 'memory']:
            if module_name in strategy['modules']:
                module_result = await self.modules[module_name].process(request, analysis, results)
                results[module_name] = module_result
                processing_path.append(module_name)

        # å¤„ç†AIæ¨¡å—ï¼ˆåœ¨æ¨ç†ä¹‹å‰ï¼‰
        if 'ai' in strategy['modules']:
            # æ„å»ºå¢å¼ºçš„ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«æ¨¡å¼æ£€æµ‹ä¿¡æ¯
            ai_context = {
                'semantic_analysis': results.get('semantic', {}),
                'memory_context': results.get('memory', {}),
                'user_id': getattr(request, 'user_id', 'anonymous'),
                'session_id': getattr(request, 'session_id', 'default')
            }

            # æ·»åŠ æ¨¡å¼æ£€æµ‹ä¿¡æ¯åˆ°AIä¸Šä¸‹æ–‡
            if hasattr(request, 'context') and request.context:
                ai_context.update({
                    'processing_mode': request.context.get('processing_mode', 'daily'),
                    'mode_confidence': request.context.get('mode_confidence', 0.5),
                    'mode_reasoning': request.context.get('mode_reasoning', ''),
                    'detection_id': request.context.get('detection_id')
                })

            # è·å–ç”¨æˆ·æŒ‡å®šçš„æ¨¡å¼
            user_preferred_mode = None
            if hasattr(request, 'context') and request.context:
                user_preferred_mode = request.context.get('user_preferred_mode')

            ai_result = await self.modules['ai'].generate_intelligent_response(
                user_input=request.input_text,
                context=ai_context,
                response_type="conversational",
                user_preferred_mode=user_preferred_mode
            )
            results['ai'] = {
                'output': ai_result.content,
                'confidence': ai_result.confidence,
                'metadata': ai_result.metadata
            }
            processing_path.append('ai')
        
        # å¤„ç†æ¨ç†æ¨¡å—
        if 'reasoning' in strategy['modules']:
            reasoning_result = await self.modules['reasoning'].process(
                request, analysis, results, depth=strategy['reasoning_depth']
            )
            results['reasoning'] = reasoning_result
            processing_path.append('reasoning')
        
        # å¤„ç†å¤šä»£ç†åä½œ
        if 'agents' in strategy['modules']:
            agent_result = await self.modules['agents'].process(request, analysis, results)
            results['agents'] = agent_result
            processing_path.append('agents')
        
        # å­¦ä¹ æ¨¡å—ï¼ˆæ€»æ˜¯æœ€åæ‰§è¡Œï¼‰
        learning_result = await self.modules['learning'].process(request, analysis, results)
        results['learning'] = learning_result
        processing_path.append('learning')
        
        return {
            'results': results,
            'processing_path': processing_path,
            'strategy': strategy
        }
    
    async def _post_process(self, request: BrainRequest, execution_result: Dict[str, Any], strategy: Dict[str, Any]) -> BrainResponse:
        """åå¤„ç†å’Œç»“æœæ•´åˆ"""
        self.logger.info("ğŸ”§ [IntelligentBrain] åå¤„ç†å’Œç»“æœæ•´åˆ...")
        
        results = execution_result['results']
        
        # æ•´åˆå„æ¨¡å—çš„è¾“å‡º
        final_output = await self._integrate_outputs(results)
        
        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = await self._calculate_confidence(results)
        
        # æ”¶é›†æ¨ç†è½¨è¿¹
        reasoning_trace = []
        for module_name, result in results.items():
            if 'reasoning_trace' in result:
                reasoning_trace.extend(result['reasoning_trace'])
        
        # æ”¶é›†è®°å¿†æ›´æ–°
        memory_updates = []
        if 'memory' in results and 'updates' in results['memory']:
            memory_updates = results['memory']['updates']
        
        return BrainResponse(
            output=final_output,
            confidence=confidence,
            processing_path=execution_result['processing_path'],
            reasoning_trace=reasoning_trace,
            memory_updates=memory_updates,
            metadata={
                'strategy': strategy,
                'module_results': {k: v.get('metadata', {}) for k, v in results.items()}
            },
            timestamp=datetime.now().isoformat()
        )
    
    async def _assess_complexity(self, text: str, semantic_analysis: Dict[str, Any]) -> ComplexityLevel:
        """è¯„ä¼°è¾“å…¥çš„å¤æ‚åº¦"""
        # ç®€å•çš„å¤æ‚åº¦è¯„ä¼°é€»è¾‘
        factors = 0
        
        # æ–‡æœ¬é•¿åº¦å› å­
        if len(text) > 200:
            factors += 1
        if len(text) > 500:
            factors += 1
            
        # è¯­ä¹‰å¤æ‚åº¦å› å­
        if semantic_analysis.get('entities_count', 0) > 3:
            factors += 1
        if semantic_analysis.get('sentiment_complexity', 0) > 0.5:
            factors += 1
        if semantic_analysis.get('requires_reasoning', False):
            factors += 2
            
        # æ˜ å°„åˆ°å¤æ‚åº¦çº§åˆ«
        if factors <= 1:
            return ComplexityLevel.LOW
        elif factors <= 3:
            return ComplexityLevel.MEDIUM
        elif factors <= 5:
            return ComplexityLevel.HIGH
        else:
            return ComplexityLevel.EXPERT
    
    async def _identify_intent(self, text: str, semantic_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è¯†åˆ«ç”¨æˆ·æ„å›¾"""
        # ä½¿ç”¨ç°æœ‰çš„æ„å›¾è¯†åˆ«ç³»ç»Ÿ
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆç°æœ‰çš„æ„å›¾è¯†åˆ«é€»è¾‘
            return {
                'primary_intent': semantic_analysis.get('intent', 'unknown'),
                'confidence': semantic_analysis.get('intent_confidence', 0.5),
                'secondary_intents': semantic_analysis.get('secondary_intents', [])
            }
        except Exception as e:
            self.logger.warning(f"æ„å›¾è¯†åˆ«å¤±è´¥: {e}")
            return {'primary_intent': 'unknown', 'confidence': 0.0, 'secondary_intents': []}
    
    async def _integrate_outputs(self, results: Dict[str, Any]) -> str:
        """æ•´åˆå„æ¨¡å—çš„è¾“å‡º"""
        try:
            # å¦‚æœæœ‰AIæ¨¡å—ï¼Œä½¿ç”¨AIç”Ÿæˆæ™ºèƒ½å“åº”
            if 'ai' in self.modules:
                # æ”¶é›†æ‰€æœ‰åˆ†æç»“æœä½œä¸ºä¸Šä¸‹æ–‡
                context = {
                    'semantic_analysis': results.get('semantic', {}),
                    'reasoning_result': results.get('reasoning', {}),
                    'memory_context': results.get('memory', {}),
                    'agent_insights': results.get('agents', {})
                }

                # ç¡®å®šå“åº”ç±»å‹
                response_type = "conversational"
                if results.get('semantic', {}).get('intent_analysis', {}).get('primary_intent') == 'question':
                    response_type = "analytical"
                elif results.get('reasoning', {}).get('complexity_score', 0) > 0.7:
                    response_type = "technical"

                # ä½¿ç”¨AIç”Ÿæˆæ™ºèƒ½å“åº”
                ai_response = await self.modules['ai'].generate_intelligent_response(
                    user_input=getattr(self, '_current_request_text', ''),
                    context=context,
                    response_type=response_type
                )

                if ai_response.confidence > 0.5:
                    return ai_response.content

            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ä¼ ç»Ÿä¼˜å…ˆçº§ï¼ˆAIä¼˜å…ˆï¼‰
            if 'ai' in results and results['ai'].get('output'):
                return results['ai']['output']
            elif 'agents' in results and results['agents'].get('output'):
                return results['agents']['output']
            elif 'reasoning' in results and results['reasoning'].get('output'):
                return results['reasoning']['output']
            elif 'semantic' in results and results['semantic'].get('output'):
                return results['semantic']['output']
            else:
                return "æˆ‘ç†è§£äº†æ‚¨çš„éœ€æ±‚ï¼Œæ­£åœ¨ä¸ºæ‚¨æä¾›æœ€åˆé€‚çš„å›ç­”ã€‚"

        except Exception as e:
            self.logger.error(f"âŒ [IntelligentBrain] è¾“å‡ºæ•´åˆå¤±è´¥: {e}")
            return "æˆ‘ç†è§£äº†æ‚¨çš„éœ€æ±‚ï¼Œè®©æˆ‘ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚"
    
    async def _calculate_confidence(self, results: Dict[str, Any]) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
        confidences = []
        for result in results.values():
            if 'confidence' in result:
                confidences.append(result['confidence'])
        
        if not confidences:
            return 0.5
        
        # ä½¿ç”¨åŠ æƒå¹³å‡
        return sum(confidences) / len(confidences)
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–å¤§è„‘ç³»ç»ŸçŠ¶æ€"""
        return {
            'initialized': self.is_initialized,
            'modules': list(self.modules.keys()),
            'processing_history_count': len(self.processing_history),
            'last_processed': self.processing_history[-1]['timestamp'] if self.processing_history else None
        }

    async def record_mode_feedback(self, detection_id: str, user_choice: str, satisfaction: int = None, comments: str = None) -> bool:
        """è®°å½•ç”¨æˆ·å¯¹æ¨¡å¼é€‰æ‹©çš„åé¦ˆ"""

        try:
            if 'ai' in self.modules:
                ai_module = self.modules['ai']
                return await ai_module.record_mode_feedback(detection_id, user_choice, satisfaction, comments)
            return False
        except Exception as e:
            self.logger.warning(f"âš ï¸ [IntelligentBrain] è®°å½•æ¨¡å¼åé¦ˆå¤±è´¥: {e}")
            return False

    async def get_mode_detection_stats(self) -> Dict[str, Any]:
        """è·å–æ¨¡å¼æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯"""

        try:
            if 'ai' in self.modules:
                ai_module = self.modules['ai']
                return await ai_module.get_mode_detection_stats()
            return {"enabled": False}
        except Exception as e:
            self.logger.warning(f"âš ï¸ [IntelligentBrain] è·å–æ¨¡å¼æ£€æµ‹ç»Ÿè®¡å¤±è´¥: {e}")
            return {"enabled": False, "error": str(e)}

    def toggle_mode_detection(self, enabled: bool) -> None:
        """å¯ç”¨æˆ–ç¦ç”¨æ¨¡å¼æ£€æµ‹"""

        try:
            if 'ai' in self.modules:
                ai_module = self.modules['ai']
                ai_module.toggle_mode_detection(enabled)
                self.logger.info(f"ğŸ¯ [IntelligentBrain] æ¨¡å¼æ£€æµ‹å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")
        except Exception as e:
            self.logger.warning(f"âš ï¸ [IntelligentBrain] åˆ‡æ¢æ¨¡å¼æ£€æµ‹çŠ¶æ€å¤±è´¥: {e}")

    async def get_supported_modes(self) -> Dict[str, Any]:
        """è·å–æ”¯æŒçš„æ¨¡å¼åˆ—è¡¨"""

        try:
            if 'ai' in self.modules:
                ai_module = self.modules['ai']
                return await ai_module.get_supported_modes()
            return {"enabled": False}
        except Exception as e:
            self.logger.warning(f"âš ï¸ [IntelligentBrain] è·å–æ”¯æŒæ¨¡å¼å¤±è´¥: {e}")
            return {"enabled": False, "error": str(e)}

    async def get_mode_info(self, mode: str) -> Dict[str, Any]:
        """è·å–ç‰¹å®šæ¨¡å¼çš„ä¿¡æ¯"""

        try:
            if 'ai' in self.modules:
                ai_module = self.modules['ai']
                return await ai_module.get_mode_info(mode)
            return {"enabled": False}
        except Exception as e:
            self.logger.warning(f"âš ï¸ [IntelligentBrain] è·å–æ¨¡å¼ä¿¡æ¯å¤±è´¥: {e}")
            return {"enabled": False, "error": str(e)}

    async def is_mode_enabled(self, mode: str) -> bool:
        """æ£€æŸ¥æ¨¡å¼æ˜¯å¦å¯ç”¨"""

        try:
            if 'ai' in self.modules:
                ai_module = self.modules['ai']
                return await ai_module.is_mode_enabled(mode)
            return False
        except Exception as e:
            self.logger.warning(f"âš ï¸ [IntelligentBrain] æ£€æŸ¥æ¨¡å¼çŠ¶æ€å¤±è´¥: {e}")
            return False

    def get_processing_history(self) -> List[Dict[str, Any]]:
        """è·å–å¤„ç†å†å²"""
        return self.processing_history.copy()
