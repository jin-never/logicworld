"""
æ™ºèƒ½å¤§è„‘æ¨¡å¼ç®¡ç†å™¨
å®ç°æ™®é€šæ¨¡å¼å’Œä¸“ä¸šæ¨¡å¼çš„åˆ‡æ¢å’Œç®¡ç†
"""

import logging
import os
from enum import Enum
from typing import Dict, Any, Optional
from dataclasses import dataclass

class ProcessingMode(Enum):
    """å¤„ç†æ¨¡å¼æšä¸¾"""
    NORMAL = "normal"       # æ™®é€šæ¨¡å¼ï¼šæ—¥å¸¸åŠå…¬ï¼Œè½»é‡çº§å¤„ç†
    PROFESSIONAL = "professional"  # ä¸“ä¸šæ¨¡å¼ï¼šæ·±åº¦åˆ†æï¼Œå¤æ‚æ¨ç†

@dataclass
class ModeConfig:
    """æ¨¡å¼é…ç½®"""
    name: str
    description: str
    ai_provider: str
    model: str
    max_tokens: int
    temperature: float
    use_langgraph: bool
    use_multi_agent: bool
    use_complex_reasoning: bool
    response_quality: str

class ModeManager:
    """æ¨¡å¼ç®¡ç†å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.current_mode = ProcessingMode.NORMAL
        self.mode_configs = self._initialize_mode_configs()
        
    def _initialize_mode_configs(self) -> Dict[ProcessingMode, ModeConfig]:
        """åˆå§‹åŒ–æ¨¡å¼é…ç½®"""
        return {
            ProcessingMode.NORMAL: ModeConfig(
                name="æ™®é€šæ¨¡å¼",
                description="æ—¥å¸¸åŠå…¬åŠ©æ‰‹ï¼šå¿«é€Ÿé—®ç­”ã€æ–‡æ¡£å¤„ç†ã€ç®€å•åˆ†æï¼Œæ³¨é‡æ•ˆç‡å’Œå®ç”¨æ€§",
                ai_provider="deepseek",
                model="deepseek-chat",
                max_tokens=1500,  # é€‚ä¸­çš„tokenæ•°é‡
                temperature=0.4,  # å¹³è¡¡çš„åˆ›é€ æ€§
                use_langgraph=False,  # ä½¿ç”¨ç®€åŒ–å·¥ä½œæµ
                use_multi_agent=False,  # å•ä¸€æ™ºèƒ½ä»£ç†
                use_complex_reasoning=True,  # é›†æˆåŸºç¡€æ¨ç†èƒ½åŠ›
                response_quality="efficient"  # å¿«é€Ÿé«˜æ•ˆ
            ),
            ProcessingMode.PROFESSIONAL: ModeConfig(
                name="ä¸“ä¸šæ¨¡å¼ (LangGraph)",
                description="LangGraphå·¥ä½œæµç¼–æ’ï¼šå¤æ‚æ¨ç†é“¾ã€å¤šä»£ç†åä½œã€æŠ€æœ¯æ¶æ„è®¾è®¡ã€æ·±åº¦åˆ†æ",
                ai_provider="deepseek",
                model="deepseek-chat",
                max_tokens=4000,  # å¤§å®¹é‡token
                temperature=0.7,  # é«˜åˆ›é€ æ€§
                use_langgraph=True,  # æ ¸å¿ƒï¼šLangGraphå·¥ä½œæµç¼–æ’
                use_multi_agent=True,  # å¤šä¸“å®¶ä»£ç†åä½œ
                use_complex_reasoning=True,  # æ·±åº¦æ¨ç†å¼•æ“
                response_quality="comprehensive"  # å…¨é¢æ·±å…¥
            )
        }
    
    def switch_mode(self, mode: ProcessingMode) -> bool:
        """åˆ‡æ¢æ¨¡å¼"""
        try:
            if mode in self.mode_configs:
                old_mode = self.current_mode
                self.current_mode = mode
                
                config = self.mode_configs[mode]
                self.logger.info(f"ğŸ”„ [ModeManager] æ¨¡å¼åˆ‡æ¢: {old_mode.value} -> {mode.value}")
                self.logger.info(f"ğŸ“‹ [ModeManager] å½“å‰é…ç½®: {config.name} - {config.description}")
                
                return True
            else:
                self.logger.error(f"âŒ [ModeManager] æœªçŸ¥æ¨¡å¼: {mode}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ [ModeManager] æ¨¡å¼åˆ‡æ¢å¤±è´¥: {e}")
            return False
    
    def get_current_mode(self) -> ProcessingMode:
        """è·å–å½“å‰æ¨¡å¼"""
        return self.current_mode
    
    def get_current_config(self) -> ModeConfig:
        """è·å–å½“å‰æ¨¡å¼é…ç½®"""
        return self.mode_configs[self.current_mode]
    
    def get_mode_info(self, mode: Optional[ProcessingMode] = None) -> Dict[str, Any]:
        """è·å–æ¨¡å¼ä¿¡æ¯"""
        target_mode = mode or self.current_mode
        config = self.mode_configs[target_mode]
        
        return {
            "mode": target_mode.value,
            "name": config.name,
            "description": config.description,
            "ai_provider": config.ai_provider,
            "model": config.model,
            "capabilities": {
                "max_tokens": config.max_tokens,
                "temperature": config.temperature,
                "langgraph": config.use_langgraph,
                "multi_agent": config.use_multi_agent,
                "complex_reasoning": config.use_complex_reasoning,
                "response_quality": config.response_quality
            }
        }
    
    def get_all_modes_info(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰æ¨¡å¼ä¿¡æ¯"""
        return {
            "current_mode": self.current_mode.value,
            "modes": {
                mode.value: self.get_mode_info(mode) 
                for mode in ProcessingMode
            }
        }
    
    def should_use_feature(self, feature: str) -> bool:
        """åˆ¤æ–­å½“å‰æ¨¡å¼æ˜¯å¦åº”è¯¥ä½¿ç”¨æŸä¸ªåŠŸèƒ½"""
        config = self.get_current_config()
        
        feature_map = {
            "langgraph": config.use_langgraph,
            "multi_agent": config.use_multi_agent,
            "complex_reasoning": config.use_complex_reasoning,
            "high_quality": config.response_quality == "comprehensive"
        }
        
        return feature_map.get(feature, False)
    
    def get_ai_params(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ¨¡å¼çš„AIå‚æ•°"""
        config = self.get_current_config()
        
        return {
            "provider": config.ai_provider,
            "model": config.model,
            "max_tokens": config.max_tokens,
            "temperature": config.temperature
        }
    
    def auto_select_mode(self, user_input: str, context: Dict[str, Any] = None) -> ProcessingMode:
        """æ ¹æ®ç”¨æˆ·è¾“å…¥è‡ªåŠ¨é€‰æ‹©æ¨¡å¼"""
        # ä¸“ä¸šæ¨¡å¼å…³é”®è¯
        professional_keywords = [
            "åˆ†æ", "è®¾è®¡", "æ¶æ„", "è§„åˆ’", "ç­–ç•¥", "æ–¹æ¡ˆ", "æŠ€æœ¯", "ç®—æ³•",
            "ç³»ç»Ÿ", "æ¡†æ¶", "ä¼˜åŒ–", "è¯„ä¼°", "ç ”ç©¶", "æ·±åº¦", "å¤æ‚", "ä¸“ä¸š",
            "å•†ä¸š", "å¸‚åœº", "ç«äº‰", "æŠ•èµ„", "é£é™©", "å†³ç­–", "ç®¡ç†", "é¢†å¯¼"
        ]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸“ä¸šå…³é”®è¯
        input_lower = user_input.lower()
        for keyword in professional_keywords:
            if keyword in input_lower:
                return ProcessingMode.PROFESSIONAL
        
        # æ£€æŸ¥ä¸Šä¸‹æ–‡å¤æ‚åº¦
        if context:
            complexity_indicators = [
                len(user_input) > 100,  # é•¿æ–‡æœ¬
                context.get("requires_analysis", False),
                context.get("complexity", "low") in ["high", "expert"]
            ]
            
            if any(complexity_indicators):
                return ProcessingMode.PROFESSIONAL
        
        # é»˜è®¤æ™®é€šæ¨¡å¼
        return ProcessingMode.NORMAL

# å…¨å±€æ¨¡å¼ç®¡ç†å™¨å®ä¾‹
mode_manager = ModeManager()
