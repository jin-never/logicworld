"""
è‡ªé€‚åº”å­¦ä¹ ä¸è¿›åŒ–æœºåˆ¶
å®ç°ç³»ç»Ÿçš„è‡ªé€‚åº”å­¦ä¹ ã€ä¸ªæ€§åŒ–é€‚åº”å’Œå®æ—¶çŸ¥è¯†æ›´æ–°èƒ½åŠ›
"""

import logging
import asyncio
import json
import sqlite3
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime, timedelta
import numpy as np
from collections import defaultdict, deque
import hashlib

# å¯¼å…¥ç°æœ‰ç³»ç»Ÿç»„ä»¶
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from agent_system.agent_factory import AgentFactory


class LearningType(Enum):
    """å­¦ä¹ ç±»å‹"""
    SUPERVISED = "supervised"       # ç›‘ç£å­¦ä¹ 
    UNSUPERVISED = "unsupervised"  # æ— ç›‘ç£å­¦ä¹ 
    REINFORCEMENT = "reinforcement" # å¼ºåŒ–å­¦ä¹ 
    TRANSFER = "transfer"           # è¿ç§»å­¦ä¹ 
    INCREMENTAL = "incremental"     # å¢é‡å­¦ä¹ 


class AdaptationType(Enum):
    """é€‚åº”ç±»å‹"""
    USER_PREFERENCE = "user_preference"     # ç”¨æˆ·åå¥½é€‚åº”
    CONTEXT_ADAPTATION = "context_adaptation" # ä¸Šä¸‹æ–‡é€‚åº”
    PERFORMANCE_OPTIMIZATION = "performance_optimization" # æ€§èƒ½ä¼˜åŒ–
    KNOWLEDGE_EXPANSION = "knowledge_expansion" # çŸ¥è¯†æ‰©å±•


@dataclass
class LearningEvent:
    """å­¦ä¹ äº‹ä»¶"""
    id: str
    event_type: LearningType
    input_data: Dict[str, Any]
    expected_output: Optional[str]
    actual_output: str
    feedback_score: float
    timestamp: str
    user_id: str
    session_id: str
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


@dataclass
class UserProfile:
    """ç”¨æˆ·æ¡£æ¡ˆ"""
    user_id: str
    preferences: Dict[str, Any]
    interaction_patterns: Dict[str, Any]
    learning_history: List[str]
    performance_metrics: Dict[str, float]
    adaptation_settings: Dict[str, Any]
    last_updated: str
    
    def __post_init__(self):
        if not hasattr(self, 'preferences'):
            self.preferences = {}
        if not hasattr(self, 'interaction_patterns'):
            self.interaction_patterns = {}
        if not hasattr(self, 'learning_history'):
            self.learning_history = []
        if not hasattr(self, 'performance_metrics'):
            self.performance_metrics = {}
        if not hasattr(self, 'adaptation_settings'):
            self.adaptation_settings = {}


@dataclass
class KnowledgeUpdate:
    """çŸ¥è¯†æ›´æ–°"""
    id: str
    knowledge_type: str
    old_knowledge: Dict[str, Any]
    new_knowledge: Dict[str, Any]
    confidence: float
    source: str
    timestamp: str
    validation_status: str = "pending"


class AdaptiveLearningSystem:
    """
    è‡ªé€‚åº”å­¦ä¹ ä¸è¿›åŒ–æœºåˆ¶
    
    åŠŸèƒ½ï¼š
    1. å®æ—¶å­¦ä¹ åé¦ˆæœºåˆ¶
    2. ç”¨æˆ·åå¥½å­¦ä¹ å’Œé€‚åº”
    3. ä¸Šä¸‹æ–‡æ„ŸçŸ¥é€‚åº”
    4. çŸ¥è¯†å›¾è°±åŠ¨æ€æ›´æ–°
    5. æ€§èƒ½æŒç»­ä¼˜åŒ–
    6. ä¸ªæ€§åŒ–æœåŠ¡å®šåˆ¶
    """
    
    def __init__(self, db_path: str = "adaptive_learning.db"):
        self.logger = logging.getLogger(__name__)
        self.db_path = db_path
        self.is_initialized = False
        
        # å­¦ä¹ äº‹ä»¶é˜Ÿåˆ—
        self.learning_queue = deque(maxlen=1000)
        
        # ç”¨æˆ·æ¡£æ¡ˆç¼“å­˜
        self.user_profiles: Dict[str, UserProfile] = {}
        
        # çŸ¥è¯†æ›´æ–°é˜Ÿåˆ—
        self.knowledge_updates = deque(maxlen=500)
        
        # å­¦ä¹ ç»Ÿè®¡
        self.learning_stats = {
            'total_events': 0,
            'successful_adaptations': 0,
            'knowledge_updates': 0,
            'user_satisfaction_trend': []
        }
        
        # é€‚åº”ç­–ç•¥
        self.adaptation_strategies = {}
        
    async def initialize(self):
        """åˆå§‹åŒ–è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿ"""
        if self.is_initialized:
            return
            
        self.logger.info("ğŸ§  [AdaptiveLearning] åˆå§‹åŒ–è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿ...")
        
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            await self._initialize_database()
            
            # åŠ è½½ç”¨æˆ·æ¡£æ¡ˆ
            await self._load_user_profiles()
            
            # åˆå§‹åŒ–é€‚åº”ç­–ç•¥
            await self._initialize_adaptation_strategies()
            
            # å¯åŠ¨åå°å­¦ä¹ ä»»åŠ¡
            await self._start_background_learning()
            
            self.is_initialized = True
            self.logger.info("âœ… [AdaptiveLearning] è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ [AdaptiveLearning] åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def process(self, request, analysis: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è‡ªé€‚åº”å­¦ä¹ è¯·æ±‚"""
        if not self.is_initialized:
            await self.initialize()
            
        self.logger.info("ğŸ§  [AdaptiveLearning] å¼€å§‹è‡ªé€‚åº”å­¦ä¹ å¤„ç†...")
        
        try:
            # 1. è·å–æˆ–åˆ›å»ºç”¨æˆ·æ¡£æ¡ˆ
            user_profile = await self._get_or_create_user_profile(request.user_id)
            
            # 2. è®°å½•å­¦ä¹ äº‹ä»¶
            learning_event = await self._record_learning_event(request, analysis, previous_results)
            
            # 3. æ‰§è¡Œé€‚åº”æ€§è°ƒæ•´
            adaptations = await self._perform_adaptations(request, analysis, user_profile, previous_results)
            
            # 4. æ›´æ–°çŸ¥è¯†åº“
            knowledge_updates = await self._update_knowledge_base(request, analysis, previous_results, adaptations)
            
            # 5. ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
            performance_improvements = await self._optimize_performance(request, analysis, user_profile)
            
            # 6. ç”Ÿæˆä¸ªæ€§åŒ–å“åº”
            personalized_response = await self._generate_personalized_response(
                request, analysis, user_profile, adaptations
            )
            
            return {
                'output': personalized_response,
                'confidence': 0.85,
                'adaptations': adaptations,
                'knowledge_updates': knowledge_updates,
                'performance_improvements': performance_improvements,
                'reasoning_trace': [
                    {
                        'module': 'adaptive_learning',
                        'action': 'learn_and_adapt',
                        'result': {
                            'learning_event_id': learning_event.id,
                            'adaptations_count': len(adaptations),
                            'knowledge_updates_count': len(knowledge_updates)
                        },
                        'timestamp': datetime.now().isoformat()
                    }
                ],
                'metadata': {
                    'user_profile_updated': True,
                    'learning_type': learning_event.event_type.value,
                    'adaptation_types': [adapt['type'] for adapt in adaptations],
                    'personalization_level': user_profile.performance_metrics.get('personalization_level', 0.5)
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ [AdaptiveLearning] å¤„ç†å¤±è´¥: {e}")
            return await self._create_fallback_learning_response(request, str(e))
    
    async def _record_learning_event(self, request, analysis: Dict[str, Any], previous_results: Dict[str, Any]) -> LearningEvent:
        """è®°å½•å­¦ä¹ äº‹ä»¶"""
        self.logger.debug("ğŸ“ [AdaptiveLearning] è®°å½•å­¦ä¹ äº‹ä»¶...")
        
        # ç”Ÿæˆäº‹ä»¶ID
        event_id = self._generate_event_id(request.input_text)
        
        # ç¡®å®šå­¦ä¹ ç±»å‹
        learning_type = await self._determine_learning_type(request, analysis, previous_results)
        
        # è®¡ç®—åé¦ˆåˆ†æ•°ï¼ˆåŸºäºä¹‹å‰çš„ç»“æœè´¨é‡ï¼‰
        feedback_score = await self._calculate_feedback_score(previous_results)
        
        # åˆ›å»ºå­¦ä¹ äº‹ä»¶
        learning_event = LearningEvent(
            id=event_id,
            event_type=learning_type,
            input_data={
                'text': request.input_text,
                'context': request.context or {},
                'analysis': self._serialize_analysis(analysis)  # åºåˆ—åŒ–analysis
            },
            expected_output=None,  # å¯ä»¥ä»ç”¨æˆ·åé¦ˆä¸­è·å–
            actual_output=previous_results.get('semantic', {}).get('output', ''),
            feedback_score=feedback_score,
            timestamp=datetime.now().isoformat(),
            user_id=request.user_id,
            session_id=request.session_id,
            metadata={
                'complexity': analysis.get('semantic_analysis', {}).get('complexity_score', 0),
                'intent': analysis.get('semantic_analysis', {}).get('intent_analysis', {}).get('primary_intent', ''),
                'emotion': analysis.get('semantic_analysis', {}).get('emotion_analysis', {}).get('emotion_type', '')
            }
        )
        
        # æ·»åŠ åˆ°å­¦ä¹ é˜Ÿåˆ—
        self.learning_queue.append(learning_event)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        await self._save_learning_event(learning_event)
        
        # æ›´æ–°ç»Ÿè®¡
        self.learning_stats['total_events'] += 1
        
        return learning_event

    def _serialize_analysis(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åºåˆ—åŒ–åˆ†æç»“æœï¼Œå¤„ç†ä¸å¯JSONåºåˆ—åŒ–çš„å¯¹è±¡"""
        if not analysis:
            return {}

        serialized = {}
        for key, value in analysis.items():
            try:
                # å°è¯•JSONåºåˆ—åŒ–æµ‹è¯•
                json.dumps(value)
                serialized[key] = value
            except (TypeError, ValueError):
                # å¦‚æœæ— æ³•åºåˆ—åŒ–ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²æˆ–åŸºæœ¬ç±»å‹
                if hasattr(value, 'value'):  # æšä¸¾ç±»å‹
                    serialized[key] = value.value
                elif hasattr(value, 'name'):  # æšä¸¾ç±»å‹
                    serialized[f"{key}_name"] = value.name
                    if hasattr(value, 'value'):
                        serialized[key] = value.value
                else:
                    serialized[key] = str(value)

        return serialized

    async def _get_or_create_user_profile(self, user_id: str) -> UserProfile:
        """è·å–æˆ–åˆ›å»ºç”¨æˆ·æ¡£æ¡ˆ"""
        if user_id in self.user_profiles:
            return self.user_profiles[user_id]
        
        # å°è¯•ä»æ•°æ®åº“åŠ è½½
        profile = await self._load_user_profile_from_db(user_id)
        
        if not profile:
            # åˆ›å»ºæ–°çš„ç”¨æˆ·æ¡£æ¡ˆ
            profile = UserProfile(
                user_id=user_id,
                preferences={
                    'response_style': 'balanced',
                    'detail_level': 'medium',
                    'language_style': 'formal',
                    'preferred_reasoning_type': 'logical'
                },
                interaction_patterns={
                    'session_length': [],
                    'question_types': [],
                    'complexity_preference': 0.5,
                    'feedback_frequency': 0.0
                },
                learning_history=[],
                performance_metrics={
                    'satisfaction_score': 0.5,
                    'engagement_level': 0.5,
                    'personalization_level': 0.0
                },
                adaptation_settings={
                    'auto_adapt': True,
                    'learning_rate': 0.1,
                    'adaptation_threshold': 0.3
                },
                last_updated=datetime.now().isoformat()
            )
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            await self._save_user_profile(profile)
        
        # ç¼“å­˜åˆ°å†…å­˜
        self.user_profiles[user_id] = profile
        return profile
    
    async def _perform_adaptations(self, request, analysis: Dict[str, Any], user_profile: UserProfile, previous_results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ‰§è¡Œé€‚åº”æ€§è°ƒæ•´"""
        self.logger.debug("ğŸ”„ [AdaptiveLearning] æ‰§è¡Œé€‚åº”æ€§è°ƒæ•´...")
        
        adaptations = []
        
        # 1. ç”¨æˆ·åå¥½é€‚åº”
        preference_adaptation = await self._adapt_to_user_preferences(request, analysis, user_profile)
        if preference_adaptation:
            adaptations.append(preference_adaptation)
        
        # 2. ä¸Šä¸‹æ–‡é€‚åº”
        context_adaptation = await self._adapt_to_context(request, analysis, user_profile)
        if context_adaptation:
            adaptations.append(context_adaptation)
        
        # 3. æ€§èƒ½ä¼˜åŒ–é€‚åº”
        performance_adaptation = await self._adapt_for_performance(request, analysis, user_profile, previous_results)
        if performance_adaptation:
            adaptations.append(performance_adaptation)
        
        # 4. çŸ¥è¯†æ‰©å±•é€‚åº”
        knowledge_adaptation = await self._adapt_knowledge_base(request, analysis, user_profile)
        if knowledge_adaptation:
            adaptations.append(knowledge_adaptation)
        
        # æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ
        await self._update_user_profile_with_adaptations(user_profile, adaptations)
        
        return adaptations
    
    async def _update_knowledge_base(self, request, analysis: Dict[str, Any], previous_results: Dict[str, Any], adaptations: List[Dict[str, Any]]) -> List[KnowledgeUpdate]:
        """æ›´æ–°çŸ¥è¯†åº“"""
        self.logger.debug("ğŸ“š [AdaptiveLearning] æ›´æ–°çŸ¥è¯†åº“...")
        
        updates = []
        
        # åŸºäºç”¨æˆ·äº¤äº’æ›´æ–°çŸ¥è¯†
        if previous_results and 'reasoning' in previous_results:
            reasoning_result = previous_results['reasoning']
            if reasoning_result.get('confidence', 0) > 0.8:
                # é«˜ç½®ä¿¡åº¦çš„æ¨ç†ç»“æœå¯ä»¥ç”¨äºçŸ¥è¯†æ›´æ–°
                update = KnowledgeUpdate(
                    id=f"kb_update_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    knowledge_type="reasoning_pattern",
                    old_knowledge={},
                    new_knowledge={
                        'pattern': reasoning_result.get('reasoning_chain', {}),
                        'context': analysis.get('semantic_analysis', {}),
                        'success_rate': reasoning_result.get('confidence', 0)
                    },
                    confidence=reasoning_result.get('confidence', 0),
                    source="user_interaction",
                    timestamp=datetime.now().isoformat()
                )
                updates.append(update)
                self.knowledge_updates.append(update)
        
        # åŸºäºé€‚åº”ç»“æœæ›´æ–°çŸ¥è¯†
        for adaptation in adaptations:
            if adaptation.get('confidence', 0) > 0.7:
                update = KnowledgeUpdate(
                    id=f"adapt_update_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    knowledge_type="adaptation_pattern",
                    old_knowledge={},
                    new_knowledge=adaptation,
                    confidence=adaptation.get('confidence', 0),
                    source="adaptation_learning",
                    timestamp=datetime.now().isoformat()
                )
                updates.append(update)
                self.knowledge_updates.append(update)
        
        # ä¿å­˜æ›´æ–°åˆ°æ•°æ®åº“
        for update in updates:
            await self._save_knowledge_update(update)
        
        self.learning_stats['knowledge_updates'] += len(updates)
        
        return updates
    
    async def _optimize_performance(self, request, analysis: Dict[str, Any], user_profile: UserProfile) -> List[Dict[str, Any]]:
        """ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½"""
        self.logger.debug("âš¡ [AdaptiveLearning] ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½...")
        
        improvements = []
        
        # åˆ†æç”¨æˆ·äº¤äº’æ¨¡å¼
        interaction_patterns = user_profile.interaction_patterns
        
        # ä¼˜åŒ–å“åº”æ—¶é—´
        if len(interaction_patterns.get('session_length', [])) > 5:
            avg_session_length = sum(interaction_patterns['session_length']) / len(interaction_patterns['session_length'])
            if avg_session_length < 30:  # çŸ­ä¼šè¯åå¥½
                improvements.append({
                    'type': 'response_optimization',
                    'description': 'ä¼˜åŒ–ä¸ºå¿«é€Ÿå“åº”æ¨¡å¼',
                    'parameters': {'max_reasoning_depth': 2, 'parallel_processing': True},
                    'confidence': 0.8
                })
        
        # ä¼˜åŒ–å¤æ‚åº¦å¤„ç†
        complexity_preference = interaction_patterns.get('complexity_preference', 0.5)
        if complexity_preference < 0.3:
            improvements.append({
                'type': 'complexity_optimization',
                'description': 'ç®€åŒ–å¤„ç†æµç¨‹',
                'parameters': {'simplify_output': True, 'reduce_technical_terms': True},
                'confidence': 0.7
            })
        elif complexity_preference > 0.7:
            improvements.append({
                'type': 'complexity_optimization',
                'description': 'å¢å¼ºæ·±åº¦åˆ†æ',
                'parameters': {'enable_deep_reasoning': True, 'detailed_explanations': True},
                'confidence': 0.7
            })
        
        return improvements
    
    async def _generate_personalized_response(self, request, analysis: Dict[str, Any], user_profile: UserProfile, adaptations: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–å“åº”"""
        # åŸºäºç”¨æˆ·åå¥½è°ƒæ•´å“åº”é£æ ¼
        preferences = user_profile.preferences
        
        base_response = "æˆ‘å·²ç»æ ¹æ®æ‚¨çš„åå¥½å’Œå†å²äº¤äº’è¿›è¡Œäº†ä¸ªæ€§åŒ–å¤„ç†ã€‚"
        
        # æ ¹æ®å“åº”é£æ ¼è°ƒæ•´
        response_style = preferences.get('response_style', 'balanced')
        if response_style == 'concise':
            base_response = "å·²ä¸ºæ‚¨ä¸ªæ€§åŒ–å¤„ç†ã€‚"
        elif response_style == 'detailed':
            base_response = "æˆ‘å·²ç»ä»”ç»†åˆ†æäº†æ‚¨çš„è¯·æ±‚ï¼Œå¹¶æ ¹æ®æ‚¨çš„ä¸ªäººåå¥½ã€å†å²äº¤äº’æ¨¡å¼å’Œå½“å‰ä¸Šä¸‹æ–‡è¿›è¡Œäº†å…¨é¢çš„ä¸ªæ€§åŒ–å¤„ç†ã€‚"
        
        # æ·»åŠ é€‚åº”ä¿¡æ¯
        if adaptations:
            adaptation_info = f"æœ¬æ¬¡è¿›è¡Œäº†{len(adaptations)}é¡¹é€‚åº”æ€§è°ƒæ•´ï¼ŒåŒ…æ‹¬ï¼š" + "ã€".join([adapt.get('description', adapt.get('type', '')) for adapt in adaptations[:3]])
            base_response += f" {adaptation_info}"
        
        return base_response

    # è¾…åŠ©æ–¹æ³•å®ç°
    async def _initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        self.logger.debug("ğŸ—„ï¸ [AdaptiveLearning] åˆå§‹åŒ–æ•°æ®åº“...")

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # åˆ›å»ºå­¦ä¹ äº‹ä»¶è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_events (
                id TEXT PRIMARY KEY,
                event_type TEXT NOT NULL,
                input_data TEXT NOT NULL,
                expected_output TEXT,
                actual_output TEXT,
                feedback_score REAL NOT NULL,
                timestamp TEXT NOT NULL,
                user_id TEXT NOT NULL,
                session_id TEXT NOT NULL,
                metadata TEXT
            )
        ''')

        # åˆ›å»ºç”¨æˆ·æ¡£æ¡ˆè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_profiles (
                user_id TEXT PRIMARY KEY,
                preferences TEXT NOT NULL,
                interaction_patterns TEXT NOT NULL,
                learning_history TEXT NOT NULL,
                performance_metrics TEXT NOT NULL,
                adaptation_settings TEXT NOT NULL,
                last_updated TEXT NOT NULL
            )
        ''')

        # åˆ›å»ºçŸ¥è¯†æ›´æ–°è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_updates (
                id TEXT PRIMARY KEY,
                knowledge_type TEXT NOT NULL,
                old_knowledge TEXT,
                new_knowledge TEXT NOT NULL,
                confidence REAL NOT NULL,
                source TEXT NOT NULL,
                timestamp TEXT NOT NULL,
                validation_status TEXT DEFAULT 'pending'
            )
        ''')

        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_learning_user ON learning_events (user_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_learning_timestamp ON learning_events (timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_knowledge_type ON knowledge_updates (knowledge_type)')

        conn.commit()
        conn.close()

    async def _load_user_profiles(self):
        """åŠ è½½ç”¨æˆ·æ¡£æ¡ˆ"""
        self.logger.debug("ğŸ“¥ [AdaptiveLearning] åŠ è½½ç”¨æˆ·æ¡£æ¡ˆ...")

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('SELECT * FROM user_profiles ORDER BY last_updated DESC LIMIT 100')
        rows = cursor.fetchall()

        for row in rows:
            profile = self._row_to_user_profile(row)
            self.user_profiles[profile.user_id] = profile

        conn.close()

        self.logger.info(f"ğŸ“¥ [AdaptiveLearning] åŠ è½½äº† {len(self.user_profiles)} ä¸ªç”¨æˆ·æ¡£æ¡ˆ")

    async def _initialize_adaptation_strategies(self):
        """åˆå§‹åŒ–é€‚åº”ç­–ç•¥"""
        self.adaptation_strategies = {
            AdaptationType.USER_PREFERENCE: {
                'threshold': 0.3,
                'learning_rate': 0.1,
                'adaptation_methods': ['preference_update', 'style_adjustment']
            },
            AdaptationType.CONTEXT_ADAPTATION: {
                'threshold': 0.4,
                'learning_rate': 0.15,
                'adaptation_methods': ['context_weighting', 'dynamic_routing']
            },
            AdaptationType.PERFORMANCE_OPTIMIZATION: {
                'threshold': 0.5,
                'learning_rate': 0.2,
                'adaptation_methods': ['parameter_tuning', 'algorithm_selection']
            },
            AdaptationType.KNOWLEDGE_EXPANSION: {
                'threshold': 0.6,
                'learning_rate': 0.05,
                'adaptation_methods': ['knowledge_integration', 'pattern_learning']
            }
        }

    async def _start_background_learning(self):
        """å¯åŠ¨åå°å­¦ä¹ ä»»åŠ¡"""
        self.logger.debug("ğŸ”„ [AdaptiveLearning] å¯åŠ¨åå°å­¦ä¹ ä»»åŠ¡...")
        # è¿™é‡Œå¯ä»¥å¯åŠ¨å¼‚æ­¥ä»»åŠ¡è¿›è¡ŒæŒç»­å­¦ä¹ 
        # ç”±äºè¿™æ˜¯æ¼”ç¤ºï¼Œæˆ‘ä»¬åªæ˜¯è®°å½•å¯åŠ¨
        pass

    def _generate_event_id(self, content: str) -> str:
        """ç”Ÿæˆäº‹ä»¶ID"""
        timestamp = datetime.now().isoformat()
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        return f"event_{timestamp}_{content_hash}"

    async def _determine_learning_type(self, request, analysis: Dict[str, Any], previous_results: Dict[str, Any]) -> LearningType:
        """ç¡®å®šå­¦ä¹ ç±»å‹"""
        # åŸºäºä¸Šä¸‹æ–‡å’Œç»“æœç¡®å®šå­¦ä¹ ç±»å‹
        if previous_results and 'reasoning' in previous_results:
            return LearningType.REINFORCEMENT
        elif analysis.get('semantic_analysis', {}).get('complexity_score', 0) > 0.7:
            return LearningType.SUPERVISED
        else:
            return LearningType.INCREMENTAL

    async def _calculate_feedback_score(self, previous_results: Dict[str, Any]) -> float:
        """è®¡ç®—åé¦ˆåˆ†æ•°"""
        if not previous_results:
            return 0.5

        # åŸºäºå„æ¨¡å—çš„ç½®ä¿¡åº¦è®¡ç®—ç»¼åˆåé¦ˆåˆ†æ•°
        confidences = []
        for module_result in previous_results.values():
            if isinstance(module_result, dict) and 'confidence' in module_result:
                confidences.append(module_result['confidence'])

        if confidences:
            return sum(confidences) / len(confidences)
        else:
            return 0.5

    async def _save_learning_event(self, event: LearningEvent):
        """ä¿å­˜å­¦ä¹ äº‹ä»¶åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO learning_events
            (id, event_type, input_data, expected_output, actual_output, feedback_score, timestamp, user_id, session_id, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            event.id,
            event.event_type.value,
            json.dumps(event.input_data, ensure_ascii=False),
            event.expected_output,
            event.actual_output,
            event.feedback_score,
            event.timestamp,
            event.user_id,
            event.session_id,
            json.dumps(event.metadata, ensure_ascii=False)
        ))

        conn.commit()
        conn.close()

    async def _load_user_profile_from_db(self, user_id: str) -> Optional[UserProfile]:
        """ä»æ•°æ®åº“åŠ è½½ç”¨æˆ·æ¡£æ¡ˆ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('SELECT * FROM user_profiles WHERE user_id = ?', (user_id,))
        row = cursor.fetchone()

        conn.close()

        if row:
            return self._row_to_user_profile(row)
        return None

    def _row_to_user_profile(self, row) -> UserProfile:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºç”¨æˆ·æ¡£æ¡ˆ"""
        return UserProfile(
            user_id=row[0],
            preferences=json.loads(row[1]),
            interaction_patterns=json.loads(row[2]),
            learning_history=json.loads(row[3]),
            performance_metrics=json.loads(row[4]),
            adaptation_settings=json.loads(row[5]),
            last_updated=row[6]
        )

    async def _save_user_profile(self, profile: UserProfile):
        """ä¿å­˜ç”¨æˆ·æ¡£æ¡ˆåˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT OR REPLACE INTO user_profiles
            (user_id, preferences, interaction_patterns, learning_history, performance_metrics, adaptation_settings, last_updated)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            profile.user_id,
            json.dumps(profile.preferences, ensure_ascii=False),
            json.dumps(profile.interaction_patterns, ensure_ascii=False),
            json.dumps(profile.learning_history, ensure_ascii=False),
            json.dumps(profile.performance_metrics, ensure_ascii=False),
            json.dumps(profile.adaptation_settings, ensure_ascii=False),
            profile.last_updated
        ))

        conn.commit()
        conn.close()

    async def _save_knowledge_update(self, update: KnowledgeUpdate):
        """ä¿å­˜çŸ¥è¯†æ›´æ–°åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO knowledge_updates
            (id, knowledge_type, old_knowledge, new_knowledge, confidence, source, timestamp, validation_status)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            update.id,
            update.knowledge_type,
            json.dumps(update.old_knowledge, ensure_ascii=False),
            json.dumps(update.new_knowledge, ensure_ascii=False),
            update.confidence,
            update.source,
            update.timestamp,
            update.validation_status
        ))

        conn.commit()
        conn.close()

    # é€‚åº”æ–¹æ³•å®ç°
    async def _adapt_to_user_preferences(self, request, analysis: Dict[str, Any], user_profile: UserProfile) -> Optional[Dict[str, Any]]:
        """é€‚åº”ç”¨æˆ·åå¥½"""
        preferences = user_profile.preferences
        current_intent = analysis.get('semantic_analysis', {}).get('intent_analysis', {}).get('primary_intent', '')

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒæ•´å“åº”é£æ ¼
        if current_intent == 'question' and preferences.get('response_style') != 'detailed':
            # ç”¨æˆ·é—®é—®é¢˜æ—¶å¯èƒ½éœ€è¦è¯¦ç»†å›ç­”
            return {
                'type': AdaptationType.USER_PREFERENCE.value,
                'description': 'è°ƒæ•´ä¸ºè¯¦ç»†å›ç­”é£æ ¼',
                'old_value': preferences.get('response_style'),
                'new_value': 'detailed',
                'confidence': 0.7,
                'reason': 'é—®é¢˜ç±»å‹è¯·æ±‚é€šå¸¸éœ€è¦è¯¦ç»†å›ç­”'
            }

        return None

    async def _adapt_to_context(self, request, analysis: Dict[str, Any], user_profile: UserProfile) -> Optional[Dict[str, Any]]:
        """é€‚åº”ä¸Šä¸‹æ–‡"""
        complexity = analysis.get('semantic_analysis', {}).get('complexity_score', 0)
        user_complexity_pref = user_profile.interaction_patterns.get('complexity_preference', 0.5)

        # å¦‚æœå½“å‰å¤æ‚åº¦ä¸ç”¨æˆ·åå¥½å·®å¼‚è¾ƒå¤§ï¼Œè¿›è¡Œé€‚åº”
        if abs(complexity - user_complexity_pref) > 0.3:
            target_complexity = (complexity + user_complexity_pref) / 2
            return {
                'type': AdaptationType.CONTEXT_ADAPTATION.value,
                'description': 'è°ƒæ•´å¤„ç†å¤æ‚åº¦ä»¥åŒ¹é…ç”¨æˆ·åå¥½',
                'old_value': complexity,
                'new_value': target_complexity,
                'confidence': 0.6,
                'reason': f'ç”¨æˆ·åå¥½å¤æ‚åº¦{user_complexity_pref}ï¼Œå½“å‰{complexity}'
            }

        return None

    async def _adapt_for_performance(self, request, analysis: Dict[str, Any], user_profile: UserProfile, previous_results: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ€§èƒ½ä¼˜åŒ–é€‚åº”"""
        # æ£€æŸ¥ä¹‹å‰ç»“æœçš„æ€§èƒ½
        if previous_results:
            avg_confidence = 0
            confidence_count = 0

            for module_result in previous_results.values():
                if isinstance(module_result, dict) and 'confidence' in module_result:
                    avg_confidence += module_result['confidence']
                    confidence_count += 1

            if confidence_count > 0:
                avg_confidence /= confidence_count

                # å¦‚æœå¹³å‡ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®æ€§èƒ½ä¼˜åŒ–
                if avg_confidence < 0.6:
                    return {
                        'type': AdaptationType.PERFORMANCE_OPTIMIZATION.value,
                        'description': 'ä¼˜åŒ–å¤„ç†æµç¨‹ä»¥æé«˜ç½®ä¿¡åº¦',
                        'old_value': avg_confidence,
                        'new_value': 'optimized_pipeline',
                        'confidence': 0.8,
                        'reason': f'å½“å‰å¹³å‡ç½®ä¿¡åº¦{avg_confidence:.2f}è¾ƒä½'
                    }

        return None

    async def _adapt_knowledge_base(self, request, analysis: Dict[str, Any], user_profile: UserProfile) -> Optional[Dict[str, Any]]:
        """çŸ¥è¯†åº“é€‚åº”"""
        # æ£€æŸ¥æ˜¯å¦é‡åˆ°æ–°çš„çŸ¥è¯†é¢†åŸŸ
        keywords = analysis.get('semantic_analysis', {}).get('surface_analysis', {}).get('keywords', [])

        # ç®€å•æ£€æŸ¥ï¼šå¦‚æœå…³é”®è¯ä¸­åŒ…å«ä¸“ä¸šæœ¯è¯­ï¼Œå¯èƒ½éœ€è¦æ‰©å±•çŸ¥è¯†åº“
        technical_keywords = ['AI', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•', 'æ•°æ®ç§‘å­¦', 'ç¼–ç¨‹']

        if any(keyword in ' '.join(keywords) for keyword in technical_keywords):
            return {
                'type': AdaptationType.KNOWLEDGE_EXPANSION.value,
                'description': 'æ‰©å±•æŠ€æœ¯é¢†åŸŸçŸ¥è¯†åº“',
                'old_value': 'basic_knowledge',
                'new_value': 'expanded_technical_knowledge',
                'confidence': 0.7,
                'reason': 'æ£€æµ‹åˆ°æŠ€æœ¯ç›¸å…³å†…å®¹ï¼Œéœ€è¦æ‰©å±•ç›¸å…³çŸ¥è¯†'
            }

        return None

    async def _update_user_profile_with_adaptations(self, user_profile: UserProfile, adaptations: List[Dict[str, Any]]):
        """æ ¹æ®é€‚åº”ç»“æœæ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ"""
        for adaptation in adaptations:
            adaptation_type = adaptation['type']

            if adaptation_type == AdaptationType.USER_PREFERENCE.value:
                # æ›´æ–°ç”¨æˆ·åå¥½
                if 'response_style' in adaptation['description']:
                    user_profile.preferences['response_style'] = adaptation['new_value']

            elif adaptation_type == AdaptationType.CONTEXT_ADAPTATION.value:
                # æ›´æ–°å¤æ‚åº¦åå¥½
                if 'complexity_preference' not in user_profile.interaction_patterns:
                    user_profile.interaction_patterns['complexity_preference'] = []
                user_profile.interaction_patterns['complexity_preference'] = adaptation['new_value']

            # è®°å½•é€‚åº”å†å²
            user_profile.learning_history.append(adaptation['description'])

            # é™åˆ¶å†å²è®°å½•é•¿åº¦
            if len(user_profile.learning_history) > 50:
                user_profile.learning_history = user_profile.learning_history[-50:]

        # æ›´æ–°æ—¶é—´æˆ³
        user_profile.last_updated = datetime.now().isoformat()

        # ä¿å­˜åˆ°æ•°æ®åº“
        await self._save_user_profile(user_profile)

        # æ›´æ–°æˆåŠŸé€‚åº”ç»Ÿè®¡
        if adaptations:
            self.learning_stats['successful_adaptations'] += len(adaptations)

    async def _create_fallback_learning_response(self, request, error_msg: str) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ç”¨å­¦ä¹ å“åº”"""
        return {
            'output': f"è‡ªé€‚åº”å­¦ä¹ é‡åˆ°é—®é¢˜ï¼š{error_msg}ã€‚ç³»ç»Ÿå°†ç»§ç»­å­¦ä¹ å’Œæ”¹è¿›ã€‚",
            'confidence': 0.3,
            'adaptations': [],
            'knowledge_updates': [],
            'performance_improvements': [],
            'reasoning_trace': [
                {
                    'module': 'adaptive_learning',
                    'action': 'fallback',
                    'error': error_msg,
                    'timestamp': datetime.now().isoformat()
                }
            ],
            'metadata': {'error': True, 'fallback': True}
        }

    # å…¬å…±æ¥å£æ–¹æ³•
    async def provide_feedback(self, event_id: str, feedback_score: float, feedback_text: str = ""):
        """æä¾›ç”¨æˆ·åé¦ˆ"""
        self.logger.info(f"ğŸ“ [AdaptiveLearning] æ”¶åˆ°åé¦ˆ: {event_id}, åˆ†æ•°: {feedback_score}")

        # æŸ¥æ‰¾å¯¹åº”çš„å­¦ä¹ äº‹ä»¶
        for event in self.learning_queue:
            if event.id == event_id:
                event.feedback_score = feedback_score
                if feedback_text:
                    event.metadata['user_feedback'] = feedback_text

                # æ›´æ–°æ•°æ®åº“
                await self._save_learning_event(event)
                break

        # æ›´æ–°ç”¨æˆ·æ»¡æ„åº¦è¶‹åŠ¿
        self.learning_stats['user_satisfaction_trend'].append(feedback_score)
        if len(self.learning_stats['user_satisfaction_trend']) > 100:
            self.learning_stats['user_satisfaction_trend'] = self.learning_stats['user_satisfaction_trend'][-100:]

    def get_learning_stats(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        recent_satisfaction = self.learning_stats['user_satisfaction_trend'][-10:] if self.learning_stats['user_satisfaction_trend'] else [0.5]

        return {
            'total_events': self.learning_stats['total_events'],
            'successful_adaptations': self.learning_stats['successful_adaptations'],
            'knowledge_updates': self.learning_stats['knowledge_updates'],
            'user_profiles_count': len(self.user_profiles),
            'recent_satisfaction_avg': sum(recent_satisfaction) / len(recent_satisfaction),
            'learning_queue_size': len(self.learning_queue),
            'knowledge_updates_pending': len([u for u in self.knowledge_updates if u.validation_status == 'pending'])
        }

    async def get_user_insights(self, user_id: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·æ´å¯Ÿ"""
        if user_id not in self.user_profiles:
            return {'error': 'User profile not found'}

        profile = self.user_profiles[user_id]

        return {
            'user_id': user_id,
            'preferences': profile.preferences,
            'interaction_summary': {
                'total_interactions': len(profile.learning_history),
                'complexity_preference': profile.interaction_patterns.get('complexity_preference', 0.5),
                'satisfaction_score': profile.performance_metrics.get('satisfaction_score', 0.5),
                'personalization_level': profile.performance_metrics.get('personalization_level', 0.0)
            },
            'recent_adaptations': profile.learning_history[-5:],
            'last_updated': profile.last_updated
        }
