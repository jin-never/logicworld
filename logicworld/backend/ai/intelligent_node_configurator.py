"""
AIæ™ºèƒ½èŠ‚ç‚¹é…ç½®å™¨
ä¸ºå››ä¸ªæ ¸å¿ƒèŠ‚ç‚¹æä¾›æ™ºèƒ½åŒ–é…ç½®å’Œä¼˜åŒ–åŠŸèƒ½
"""
import json
import logging
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

from ai.brain_system.brain_core import IntelligentBrain
from ai.brain_system.ai_integration import IntelligentAIIntegration


class NodeType(Enum):
    """èŠ‚ç‚¹ç±»å‹"""
    MATERIAL = "material-node"
    EXECUTION = "execution-node"
    CONDITION = "condition-node"
    RESULT = "result-node"


@dataclass
class NodeConfigRequest:
    """èŠ‚ç‚¹é…ç½®è¯·æ±‚"""
    node_type: NodeType
    user_description: str
    context: Dict[str, Any]
    workflow_context: Dict[str, Any]
    existing_config: Dict[str, Any] = None


@dataclass
class NodeConfigResponse:
    """èŠ‚ç‚¹é…ç½®å“åº”"""
    success: bool
    config: Dict[str, Any]
    reasoning: str
    confidence: float
    suggestions: List[str]
    optimizations: List[Dict[str, Any]]


class IntelligentNodeConfigurator:
    """æ™ºèƒ½èŠ‚ç‚¹é…ç½®å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.brain = None
        self.ai_integration = None
        
        # èŠ‚ç‚¹é…ç½®æ¨¡æ¿
        self.node_templates = {
            NodeType.MATERIAL: {
                "default_config": {
                    "auto_detection": True,
                    "supported_formats": ["txt", "pdf", "docx", "xlsx", "csv", "json", "xml"],
                    "preprocessing": {
                        "auto_extract": True,
                        "format_conversion": True,
                        "quality_check": True
                    },
                    "organization": {
                        "auto_categorize": True,
                        "duplicate_detection": True,
                        "version_control": True
                    }
                },
                "intelligence_features": [
                    "auto_type_detection",
                    "content_analysis", 
                    "dependency_mapping",
                    "quality_assessment",
                    "preprocessing_suggestions"
                ]
            },
            NodeType.EXECUTION: {
                "default_config": {
                    "execution_type": "ai-task",  # é»˜è®¤ä¸ºAIä»»åŠ¡æ‰§è¡Œ
                    "ai_model": "deepseek",  # é»˜è®¤ä½¿ç”¨DeepSeekæ¨¡å‹
                    "auto_tool_selection": True,
                    "parameter_optimization": True,
                    "error_handling": {
                        "auto_retry": True,
                        "fallback_strategies": True,
                        "error_recovery": True
                    },
                    "performance": {
                        "parallel_execution": True,
                        "resource_optimization": True,
                        "progress_tracking": True
                    }
                },
                "intelligence_features": [
                    "task_decomposition",
                    "tool_auto_selection",
                    "parameter_intelligence",
                    "execution_optimization",
                    "performance_prediction"
                ]
            },
            NodeType.CONDITION: {
                "default_config": {
                    "condition_type": "intelligent",
                    "auto_logic_generation": True,
                    "dynamic_evaluation": True,
                    "learning": {
                        "user_preference_learning": True,
                        "pattern_recognition": True,
                        "decision_optimization": True
                    },
                    "validation": {
                        "logic_verification": True,
                        "edge_case_handling": True,
                        "consistency_check": True
                    }
                },
                "intelligence_features": [
                    "logical_reasoning",
                    "dynamic_branching",
                    "quality_checking",
                    "preference_learning",
                    "intelligent_fallback"
                ]
            },
            NodeType.RESULT: {
                "default_config": {
                    "output_optimization": True,
                    "format_intelligence": True,
                    "quality_enhancement": True,
                    "distribution": {
                        "auto_format_selection": True,
                        "multi_version_generation": True,
                        "compatibility_check": True
                    },
                    "post_processing": {
                        "auto_enhancement": True,
                        "metadata_generation": True,
                        "version_management": True
                    }
                },
                "intelligence_features": [
                    "format_intelligence",
                    "quality_optimization",
                    "multi_version_management",
                    "distribution_strategy",
                    "post_processing_automation"
                ]
            }
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–é…ç½®å™¨"""
        try:
            self.brain = IntelligentBrain()
            await self.brain.initialize()
            
            self.ai_integration = IntelligentAIIntegration()
            await self.ai_integration.initialize()
            
            self.logger.info("ğŸ¤– æ™ºèƒ½èŠ‚ç‚¹é…ç½®å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"æ™ºèƒ½èŠ‚ç‚¹é…ç½®å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def configure_node(self, request: NodeConfigRequest) -> NodeConfigResponse:
        """æ™ºèƒ½é…ç½®èŠ‚ç‚¹"""
        if not self.brain:
            await self.initialize()
        
        self.logger.info(f"ğŸ”§ å¼€å§‹æ™ºèƒ½é…ç½® {request.node_type.value} èŠ‚ç‚¹")
        
        try:
            # 1. åˆ†æç”¨æˆ·éœ€æ±‚å’Œä¸Šä¸‹æ–‡
            analysis = await self._analyze_node_requirements(request)
            
            # 2. ç”Ÿæˆæ™ºèƒ½é…ç½®
            config = await self._generate_intelligent_config(request, analysis)
            
            # 3. ä¼˜åŒ–é…ç½®
            optimized_config = await self._optimize_config(config, request, analysis)
            
            # 4. éªŒè¯é…ç½®
            validation_result = await self._validate_config(optimized_config, request)
            
            # 5. ç”Ÿæˆå»ºè®®å’Œä¼˜åŒ–æ–¹æ¡ˆ
            suggestions = await self._generate_suggestions(optimized_config, request, analysis)
            optimizations = await self._generate_optimizations(optimized_config, request, analysis)
            
            return NodeConfigResponse(
                success=True,
                config=optimized_config,
                reasoning=analysis.get('reasoning', ''),
                confidence=validation_result.get('confidence', 0.8),
                suggestions=suggestions,
                optimizations=optimizations
            )
            
        except Exception as e:
            self.logger.error(f"èŠ‚ç‚¹é…ç½®å¤±è´¥: {e}")
            return NodeConfigResponse(
                success=False,
                config=self._get_fallback_config(request.node_type),
                reasoning=f"é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {str(e)}",
                confidence=0.3,
                suggestions=[],
                optimizations=[]
            )
    
    async def _analyze_node_requirements(self, request: NodeConfigRequest) -> Dict[str, Any]:
        """åˆ†æèŠ‚ç‚¹éœ€æ±‚"""
        analysis_prompt = f"""
        åˆ†æä»¥ä¸‹èŠ‚ç‚¹é…ç½®éœ€æ±‚ï¼š
        
        èŠ‚ç‚¹ç±»å‹: {request.node_type.value}
        ç”¨æˆ·æè¿°: {request.user_description}
        ä¸Šä¸‹æ–‡ä¿¡æ¯: {json.dumps(request.context, ensure_ascii=False, indent=2)}
        å·¥ä½œæµä¸Šä¸‹æ–‡: {json.dumps(request.workflow_context, ensure_ascii=False, indent=2)}
        
        è¯·åˆ†æå¹¶è¿”å›JSONæ ¼å¼çš„ç»“æœï¼ŒåŒ…å«ï¼š
        1. requirements: å…·ä½“éœ€æ±‚åˆ—è¡¨
        2. constraints: çº¦æŸæ¡ä»¶
        3. optimization_goals: ä¼˜åŒ–ç›®æ ‡
        4. intelligence_level: æ‰€éœ€æ™ºèƒ½åŒ–ç¨‹åº¦ (basic/intermediate/advanced)
        5. reasoning: åˆ†ææ¨ç†è¿‡ç¨‹
        6. recommended_features: æ¨èçš„æ™ºèƒ½åŒ–åŠŸèƒ½
        """
        
        try:
            response = await self.ai_integration.generate_intelligent_response(
                user_input=analysis_prompt,
                context=request.context,
                response_type="analytical"
            )
            
            # å°è¯•è§£æJSONå“åº”
            if hasattr(response, 'content'):
                analysis_text = response.content
            else:
                analysis_text = str(response)
            
            # æå–JSONéƒ¨åˆ†
            json_start = analysis_text.find('{')
            json_end = analysis_text.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                analysis = json.loads(analysis_text[json_start:json_end])
            else:
                # å¦‚æœæ— æ³•è§£æJSONï¼Œä½¿ç”¨è§„åˆ™åŸºç¡€åˆ†æ
                analysis = await self._rule_based_analysis(request)
            
            return analysis
            
        except Exception as e:
            self.logger.warning(f"AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™åŸºç¡€åˆ†æ: {e}")
            return await self._rule_based_analysis(request)
    
    async def _rule_based_analysis(self, request: NodeConfigRequest) -> Dict[str, Any]:
        """åŸºäºè§„åˆ™çš„åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        node_type = request.node_type
        description = request.user_description.lower()
        
        # åŸºç¡€åˆ†æé€»è¾‘
        requirements = []
        constraints = []
        optimization_goals = []
        intelligence_level = "intermediate"
        
        if node_type == NodeType.MATERIAL:
            if any(word in description for word in ['æ–‡ä»¶', 'æ–‡æ¡£', 'å›¾ç‰‡', 'æ•°æ®']):
                requirements.extend(['æ–‡ä»¶å¤„ç†', 'æ ¼å¼è¯†åˆ«', 'å†…å®¹æå–'])
            if any(word in description for word in ['æ‰¹é‡', 'å¤§é‡', 'å¤šä¸ª']):
                optimization_goals.append('æ‰¹é‡å¤„ç†ä¼˜åŒ–')
                intelligence_level = "advanced"
        
        elif node_type == NodeType.EXECUTION:
            if any(word in description for word in ['AI', 'æ™ºèƒ½', 'è‡ªåŠ¨']):
                requirements.extend(['AIä»»åŠ¡æ‰§è¡Œ', 'æ™ºèƒ½å‚æ•°é…ç½®'])
                intelligence_level = "advanced"
            if any(word in description for word in ['å·¥å…·', 'è°ƒç”¨', 'API']):
                requirements.extend(['å·¥å…·è°ƒç”¨', 'APIé›†æˆ'])
        
        elif node_type == NodeType.CONDITION:
            if any(word in description for word in ['åˆ¤æ–­', 'æ¡ä»¶', 'åˆ†æ”¯']):
                requirements.extend(['é€»è¾‘åˆ¤æ–­', 'æ¡ä»¶è¯„ä¼°'])
            if any(word in description for word in ['å¤æ‚', 'å¤šæ¡ä»¶']):
                intelligence_level = "advanced"
        
        elif node_type == NodeType.RESULT:
            if any(word in description for word in ['æŠ¥å‘Š', 'æ–‡æ¡£', 'è¾“å‡º']):
                requirements.extend(['æ ¼å¼åŒ–è¾“å‡º', 'è´¨é‡ä¼˜åŒ–'])
            if any(word in description for word in ['å¤šç§', 'æ ¼å¼', 'ç‰ˆæœ¬']):
                optimization_goals.append('å¤šæ ¼å¼æ”¯æŒ')
        
        return {
            'requirements': requirements,
            'constraints': constraints,
            'optimization_goals': optimization_goals,
            'intelligence_level': intelligence_level,
            'reasoning': f'åŸºäºå…³é”®è¯åˆ†æ {node_type.value} èŠ‚ç‚¹éœ€æ±‚',
            'recommended_features': self.node_templates[node_type]['intelligence_features']
        }

    async def _generate_intelligent_config(self, request: NodeConfigRequest, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½é…ç½®"""
        base_config = self.node_templates[request.node_type]['default_config'].copy()

        # æ ¹æ®åˆ†æç»“æœè°ƒæ•´é…ç½®
        intelligence_level = analysis.get('intelligence_level', 'intermediate')
        requirements = analysis.get('requirements', [])

        if request.node_type == NodeType.MATERIAL:
            config = await self._configure_material_node(base_config, requirements, analysis)
        elif request.node_type == NodeType.EXECUTION:
            config = await self._configure_execution_node(base_config, requirements, analysis)
        elif request.node_type == NodeType.CONDITION:
            config = await self._configure_condition_node(base_config, requirements, analysis)
        elif request.node_type == NodeType.RESULT:
            config = await self._configure_result_node(base_config, requirements, analysis)
        else:
            config = base_config

        # åº”ç”¨æ™ºèƒ½åŒ–çº§åˆ«è°ƒæ•´
        config = self._apply_intelligence_level(config, intelligence_level)

        return config

    async def _configure_material_node(self, base_config: Dict[str, Any],
                                     requirements: List[str],
                                     analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é…ç½®ææ–™èŠ‚ç‚¹"""
        config = base_config.copy()

        # æ ¹æ®éœ€æ±‚è°ƒæ•´é…ç½®
        if 'æ–‡ä»¶å¤„ç†' in requirements:
            config['preprocessing']['auto_extract'] = True
            config['preprocessing']['format_conversion'] = True

        if 'æ‰¹é‡å¤„ç†ä¼˜åŒ–' in analysis.get('optimization_goals', []):
            config['batch_processing'] = {
                'enabled': True,
                'parallel_processing': True,
                'chunk_size': 'auto'
            }

        # æ™ºèƒ½æ–‡ä»¶ç±»å‹æ£€æµ‹
        config['intelligence'] = {
            'auto_type_detection': True,
            'content_analysis': True,
            'dependency_mapping': True,
            'quality_assessment': True
        }

        return config

    async def _configure_execution_node(self, base_config: Dict[str, Any],
                                       requirements: List[str],
                                       analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é…ç½®æ‰§è¡ŒèŠ‚ç‚¹"""
        config = base_config.copy()

        # æ ¹æ®éœ€æ±‚è°ƒæ•´æ‰§è¡Œç±»å‹
        if 'AIä»»åŠ¡æ‰§è¡Œ' in requirements:
            config['execution_type'] = 'ai-execution'
            config['ai_config'] = {
                'model_selection': 'auto',
                'parameter_optimization': True,
                'context_awareness': True
            }

        if 'å·¥å…·è°ƒç”¨' in requirements:
            config['tool_integration'] = {
                'auto_tool_selection': True,
                'parameter_mapping': True,
                'error_handling': True
            }

        # æ™ºèƒ½ä»»åŠ¡åˆ†è§£
        config['intelligence'] = {
            'task_decomposition': True,
            'execution_optimization': True,
            'performance_prediction': True,
            'adaptive_retry': True
        }

        return config

    async def _configure_condition_node(self, base_config: Dict[str, Any],
                                       requirements: List[str],
                                       analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é…ç½®æ¡ä»¶èŠ‚ç‚¹"""
        config = base_config.copy()

        # æ™ºèƒ½é€»è¾‘ç”Ÿæˆ
        if 'é€»è¾‘åˆ¤æ–­' in requirements:
            config['logic_generation'] = {
                'auto_condition_creation': True,
                'natural_language_input': True,
                'logic_optimization': True
            }

        # åŠ¨æ€åˆ†æ”¯
        config['intelligence'] = {
            'logical_reasoning': True,
            'dynamic_branching': True,
            'quality_checking': True,
            'preference_learning': True
        }

        return config

    async def _configure_result_node(self, base_config: Dict[str, Any],
                                    requirements: List[str],
                                    analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é…ç½®ç»“æœèŠ‚ç‚¹"""
        config = base_config.copy()

        # æ ¼å¼åŒ–è¾“å‡º
        if 'æ ¼å¼åŒ–è¾“å‡º' in requirements:
            config['output_formatting'] = {
                'auto_format_selection': True,
                'template_generation': True,
                'quality_enhancement': True
            }

        # å¤šæ ¼å¼æ”¯æŒ
        if 'å¤šæ ¼å¼æ”¯æŒ' in analysis.get('optimization_goals', []):
            config['multi_format'] = {
                'enabled': True,
                'formats': ['pdf', 'docx', 'html', 'json', 'csv'],
                'auto_conversion': True
            }

        # æ™ºèƒ½ä¼˜åŒ–
        config['intelligence'] = {
            'format_intelligence': True,
            'quality_optimization': True,
            'distribution_strategy': True,
            'metadata_generation': True
        }

        return config

    def _apply_intelligence_level(self, config: Dict[str, Any], level: str) -> Dict[str, Any]:
        """åº”ç”¨æ™ºèƒ½åŒ–çº§åˆ«"""
        if level == 'basic':
            # åŸºç¡€çº§åˆ«ï¼šå…³é—­é«˜çº§åŠŸèƒ½
            if 'intelligence' in config:
                for key in config['intelligence']:
                    if key in ['advanced_reasoning', 'deep_learning', 'complex_optimization']:
                        config['intelligence'][key] = False

        elif level == 'advanced':
            # é«˜çº§çº§åˆ«ï¼šå¯ç”¨æ‰€æœ‰æ™ºèƒ½åŠŸèƒ½
            if 'intelligence' not in config:
                config['intelligence'] = {}

            config['intelligence'].update({
                'advanced_reasoning': True,
                'deep_learning': True,
                'complex_optimization': True,
                'predictive_analysis': True,
                'adaptive_behavior': True
            })

        return config

    async def _optimize_config(self, config: Dict[str, Any],
                              request: NodeConfigRequest,
                              analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼˜åŒ–é…ç½®"""
        optimized_config = config.copy()

        # æ€§èƒ½ä¼˜åŒ–
        if 'performance' not in optimized_config:
            optimized_config['performance'] = {}

        optimized_config['performance'].update({
            'caching': True,
            'lazy_loading': True,
            'resource_management': True
        })

        # æ ¹æ®å·¥ä½œæµä¸Šä¸‹æ–‡ä¼˜åŒ–
        workflow_context = request.workflow_context
        if workflow_context.get('high_volume', False):
            optimized_config['performance']['parallel_processing'] = True
            optimized_config['performance']['batch_optimization'] = True

        return optimized_config

    async def _validate_config(self, config: Dict[str, Any],
                              request: NodeConfigRequest) -> Dict[str, Any]:
        """éªŒè¯é…ç½®"""
        validation_result = {
            'valid': True,
            'confidence': 0.8,
            'issues': [],
            'warnings': []
        }

        # åŸºç¡€éªŒè¯
        required_fields = ['intelligence']
        for field in required_fields:
            if field not in config:
                validation_result['issues'].append(f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}')
                validation_result['valid'] = False

        # èŠ‚ç‚¹ç‰¹å®šéªŒè¯
        if request.node_type == NodeType.EXECUTION:
            if 'execution_type' not in config:
                validation_result['warnings'].append('æœªæŒ‡å®šæ‰§è¡Œç±»å‹ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼')

        # è®¡ç®—ç½®ä¿¡åº¦
        if validation_result['issues']:
            validation_result['confidence'] *= 0.5
        if validation_result['warnings']:
            validation_result['confidence'] *= 0.9

        return validation_result

    async def _generate_suggestions(self, config: Dict[str, Any],
                                   request: NodeConfigRequest,
                                   analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå»ºè®®"""
        suggestions = []

        # åŸºäºèŠ‚ç‚¹ç±»å‹çš„å»ºè®®
        if request.node_type == NodeType.MATERIAL:
            suggestions.append("å»ºè®®å¯ç”¨è‡ªåŠ¨æ–‡ä»¶ç±»å‹æ£€æµ‹ä»¥æé«˜å¤„ç†æ•ˆç‡")
            if not config.get('preprocessing', {}).get('quality_check'):
                suggestions.append("å»ºè®®å¯ç”¨è´¨é‡æ£€æŸ¥ä»¥ç¡®ä¿æ•°æ®å®Œæ•´æ€§")

        elif request.node_type == NodeType.EXECUTION:
            suggestions.append("å»ºè®®ä½¿ç”¨AIæ‰§è¡Œæ¨¡å¼ä»¥è·å¾—æ›´å¥½çš„ä»»åŠ¡ç†è§£èƒ½åŠ›")
            if not config.get('error_handling', {}).get('auto_retry'):
                suggestions.append("å»ºè®®å¯ç”¨è‡ªåŠ¨é‡è¯•æœºåˆ¶ä»¥æé«˜æ‰§è¡ŒæˆåŠŸç‡")

        elif request.node_type == NodeType.CONDITION:
            suggestions.append("å»ºè®®ä½¿ç”¨æ™ºèƒ½é€»è¾‘ç”Ÿæˆä»¥ç®€åŒ–æ¡ä»¶é…ç½®")
            suggestions.append("å¯ç”¨ç”¨æˆ·åå¥½å­¦ä¹ å¯ä»¥æé«˜å†³ç­–å‡†ç¡®æ€§")

        elif request.node_type == NodeType.RESULT:
            suggestions.append("å»ºè®®å¯ç”¨å¤šæ ¼å¼è¾“å‡ºä»¥æ»¡è¶³ä¸åŒéœ€æ±‚")
            suggestions.append("è‡ªåŠ¨è´¨é‡ä¼˜åŒ–å¯ä»¥æå‡è¾“å‡ºæ•ˆæœ")

        return suggestions

    async def _generate_optimizations(self, config: Dict[str, Any],
                                     request: NodeConfigRequest,
                                     analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ"""
        optimizations = []

        # æ€§èƒ½ä¼˜åŒ–
        optimizations.append({
            'type': 'performance',
            'title': 'æ€§èƒ½ä¼˜åŒ–',
            'description': 'å¯ç”¨å¹¶è¡Œå¤„ç†å’Œç¼“å­˜æœºåˆ¶',
            'impact': 'high',
            'config_changes': {
                'performance.parallel_processing': True,
                'performance.caching': True
            }
        })

        # æ™ºèƒ½åŒ–ä¼˜åŒ–
        optimizations.append({
            'type': 'intelligence',
            'title': 'æ™ºèƒ½åŒ–å¢å¼º',
            'description': 'å¯ç”¨é«˜çº§AIåŠŸèƒ½å’Œè‡ªé€‚åº”è¡Œä¸º',
            'impact': 'medium',
            'config_changes': {
                'intelligence.advanced_reasoning': True,
                'intelligence.adaptive_behavior': True
            }
        })

        return optimizations

    def _get_fallback_config(self, node_type: NodeType) -> Dict[str, Any]:
        """è·å–å¤‡ç”¨é…ç½®"""
        return self.node_templates[node_type]['default_config'].copy()
